{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb547134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically set base path to the project directory where the notebook is running\n",
    "from pathlib import Path\n",
    "\n",
    "# This gets the directory where the current notebook is located\n",
    "base_path = Path.cwd()\n",
    "\n",
    "print(f\"ðŸ“‚ Base path automatically set to: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pzQ2WIjuqtq6",
   "metadata": {
    "id": "pzQ2WIjuqtq6"
   },
   "source": [
    "# ðŸ“Š HDF5 Data Processing with Python and ChatGPT\n",
    "\n",
    "Welcome to **HDF5 Data Processing**! In this session, we will use **ChatGPT**, **HDF5**, and **Python** to efficiently store, manipulate, and analyze large datasets.\n",
    "\n",
    "### Enable the Table of Contents Sidebar in Jupyter Notebook  \n",
    "For easier navigation:\n",
    "\n",
    "1. Click on **View** in Jupyter Notebook.\n",
    "2. Select **Left Sidebar** click **Show Table of Contents**.\n",
    "\n",
    "## What You Will Learn\n",
    "1. Set up your computer for **Python scripting** and **HDF5 file processing**.\n",
    "2. Use **ChatGPT** to generate and debug **HDF5 queries**.\n",
    "3. Learn best practices for **efficient data management** with HDF5.\n",
    "4. Process and analyze **HDF5 datasets** using **Python and Numpy**.\n",
    "\n",
    "## Required Programs\n",
    "- **Python** (Version 3.12 or later)\n",
    "- **HDF5 View** (Library for hierarchical data storage)\n",
    "- **h5py** (Python library for working with HDF5 files)\n",
    "- **Numpy** (For reading and analyzing HDF5 data)\n",
    "\n",
    "---\n",
    "\n",
    "## â–¶ï¸ Run the Test Cell  \n",
    "Before we begin, run the test cell below to check your setup.\n",
    "\n",
    "This test will:\n",
    "- âœ… Verify that **HDF5 (h5py)** is available.\n",
    "- âœ… Check if **Pandas** is installed.\n",
    "- âœ… Confirm that an **HDF5 file can be created and accessed**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd8d6c-3376-4145-a74f-2a5868b5b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking HDF5 and Pandas Setup\n",
    "\n",
    "print(\"ðŸ” Checking system setup...\\n\")\n",
    "\n",
    "# Test h5py (HDF5 support)\n",
    "try:\n",
    "    import h5py\n",
    "    with h5py.File(\"test.hdf5\", \"w\") as f:\n",
    "        f.create_dataset(\"test_data\", data=[1, 2, 3, 4, 5])\n",
    "    print(\"âœ… HDF5 (h5py) is available and working!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ HDF5 test failed: {e}\")\n",
    "\n",
    "# Test Pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"âœ… Pandas imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Pandas is not installed. Run `pip install pandas`.\")\n",
    "\n",
    "# Confirm Python version\n",
    "import sys\n",
    "print(f\"ðŸ Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "print(\"\\nâœ… Test complete! If you see any âŒ marks, install missing dependencies before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1198b-2ee0-467f-971f-1b05357f5db8",
   "metadata": {},
   "source": [
    "# ðŸ“Š HDF5 Data Structure\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Use ChatGPT to help you understand and analyze HDF5 data. Before performing any analysis, it's important to understand the file structure so you can ask ChatGPT the right questions for tasks like calculating shear stress.\n",
    "\n",
    "## Key Components of the HDF5 File\n",
    "- **Depth Data**: Stored in `TIMDEP NETCDF OUTPUT RESULTS/FLOW DEPTH/Values`, containing depth values for each grid element over time.\n",
    "- **Velocity Data**: Located in `TIMDEP NETCDF OUTPUT RESULTS/Velocity MAG/Values`, holding velocity data for each grid element.\n",
    "- **Time Intervals**: Found in `TIMDEP NETCDF OUTPUT RESULTS/FLOW DEPTH/Times`, representing the time steps for the depth and velocity data.\n",
    "- **Grid Elements**: Organized by columns for each grid element in fplain.dat and cadpts.dat, with rows representing different time steps.\n",
    "\n",
    "## Instructions\n",
    "1. Ask ChatGPT to write a script that can print the structure of an hdf5 file.\n",
    "2. Remember to add important details like the name and path of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f96903-0e16-4d6b-a8a0-cc3bfe729004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def print_structure(hdf5_file):\n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        print(f\"Structure of {hdf5_file}:\")\n",
    "        file.visititems(print_name_and_shape)\n",
    "\n",
    "def print_name_and_shape(name, obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(f\"Dataset: {name} - Shape: {obj.shape}, Dtype: {obj.dtype}\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        print(f\"Group: {name}\")\n",
    "\n",
    "# File paths\n",
    "# file_path_1 = base_path / 'Data' / 'Hdf5' / 'TIMDEP.HDF5'\n",
    "file_path_2 = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Print the structure of both files\n",
    "#print_structure(file_path_1)\n",
    "print_structure(file_path_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a0d66-1fc9-494a-81c3-5543df2da734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def list_hdf5_structure(file_path):\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        def print_structure(name, obj):\n",
    "            print(name)\n",
    "            for key, val in obj.attrs.items():\n",
    "                print(f\"  Attribute: {key}: {val}\")\n",
    "\n",
    "        file.visititems(print_structure)\n",
    "\n",
    "# Specify the path to your HDF5 file\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# List the structure of the HDF5 file\n",
    "list_hdf5_structure(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1dcda8-0717-4302-a1f5-6141aa5f62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def remove_selected_datasets(file_path):\n",
    "    with h5py.File(file_path, 'a') as file:  # Open the file in append mode to allow modifications\n",
    "        # List of datasets to remove\n",
    "        datasets_to_remove = [\n",
    "            \"TIMDEP NETCDF OUTPUT RESULTS/dep_x_vel\",\n",
    "            \"TIMDEP NETCDF OUTPUT RESULTS/dep_x_vel_x_vel\"\n",
    "        ]\n",
    "\n",
    "        # Remove datasets\n",
    "        for dataset in datasets_to_remove:\n",
    "            if dataset in file:\n",
    "                del file[dataset]\n",
    "                print(f\"Removed dataset: {dataset}\")\n",
    "            else:\n",
    "                print(f\"Dataset not found: {dataset}\")\n",
    "\n",
    "# Specify the path to your HDF5 file\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Remove the specified datasets from the HDF5 file\n",
    "remove_selected_datasets(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bc8ab-7254-41f3-9519-4846684c5b94",
   "metadata": {},
   "source": [
    "# ðŸ“Š HDF5 Depth * Velocity\n",
    "\n",
    "## Purpose\n",
    "This script uses depth and velocity data from an HDF5 file to create a new table called `DepXVel` and fill that table with the depth * velocity over time data.\n",
    "\n",
    "### Examples of Operations:\n",
    "- **Read depth and velocity data from HDF5**: This data is used to calculate depth * velocity.\n",
    "- **Create a new table**: The results are saved back into the file for further analysis.\n",
    "\n",
    "## Instructions\n",
    "1. **HDF5 read tables**: Ask ChatGPT for a script to read depth, velocity, and calculate a depth * velocity table.\n",
    "2. **Clarify the Query**: Feed the appropriate structure of the HDF5 file.\n",
    "3. **Save the results**: Ask ChatGPT to update the script by writing the results to a new table called `DepXVel` in the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f16da8-506d-4653-a220-27d289f0d8ba",
   "metadata": {},
   "source": [
    "## Example ChatGPT Query\n",
    "\n",
    "- **Objective**: Create a Python script to manipulate HDF5 file data.\n",
    "- **File Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Hdf5\\TIMDEPNC.HDF5`\n",
    "- **Data Tasks**:\n",
    "  - **Add Table `dep_x_vel`**: Multiply depth and velocity data.\n",
    "  - **Add Table `dep_x_sqvel`**: Multiply depth by velocity squared.\n",
    "- **Groups and Datasets**:\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/FLOW DEPTH`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/MAX VEL`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "- **Operations**:\n",
    "  - **Delete Existing Datasets**: Check and delete existing datasets `dep_x_vel` and `dep_x_sqvel` if present.\n",
    "  - **Calculate and Store New Data**: Compute and store new datasets for `dep_x_vel` and `dep_x_sqvel`.\n",
    "- **Dependencies**: Utilize `h5py` for HDF5 interaction and `numpy` for mathematical operations.\n",
    "- **Request**: Provide a Python script that executes the above operations as described.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f7946-edbe-4b6d-bfd0-f1c9536206fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# File path\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as hdf:\n",
    "    # Access the depth and velocity datasets\n",
    "    depth_values = hdf['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values'][:]\n",
    "    velocity_values = hdf['TIMDEP OUTPUT RESULTS/MAX VEL/Values'][:]\n",
    "\n",
    "    # Calculate depth * velocity\n",
    "    dep_x_vel = np.multiply(depth_values, velocity_values)\n",
    "    \n",
    "    # Calculate depth * velocity^2\n",
    "    dep_x_sqvel = np.multiply(depth_values, np.square(velocity_values))\n",
    "    \n",
    "    # Check and delete the old 'dep_x_vel' dataset if it exists\n",
    "    if 'dep_x_vel' in hdf['TIMDEP OUTPUT RESULTS']:\n",
    "        del hdf['TIMDEP OUTPUT RESULTS/dep_x_vel']\n",
    "    \n",
    "    # Create a new dataset for dep_x_vel\n",
    "    hdf.create_dataset('TIMDEP OUTPUT RESULTS/dep_x_vel', data=dep_x_vel, dtype='float32')\n",
    "    \n",
    "    # Check and delete the old 'dep_x_sqvel' dataset if it exists\n",
    "    if 'dep_x_sqvel' in hdf['TIMDEP OUTPUT RESULTS']:\n",
    "        del hdf['TIMDEP OUTPUT RESULTS/dep_x_sqvel']\n",
    "    \n",
    "    # Create a new dataset for dep_x_sqvel\n",
    "    hdf.create_dataset('TIMDEP OUTPUT RESULTS/dep_x_sqvel', data=dep_x_sqvel, dtype='float32')\n",
    "\n",
    "    print(\"Updated HDF5 file with new datasets after removing old ones.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017a551-7ca3-477b-8703-a6d099f980cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def add_floodwave_arrival_table(file_path):\n",
    "    with h5py.File(file_path, 'a') as file:\n",
    "        # Access the existing depth and time data from the specified group and tables\n",
    "        depth_data = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values'][:]\n",
    "        time_data = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times'][:]\n",
    "\n",
    "        # Initialize an array to store the time of first exceedance for each grid\n",
    "        time_to_1_ft = np.full((depth_data.shape[1],), np.nan)  # Use nan to indicate no exceedance\n",
    "        \n",
    "        # Depth threshold for floodwave arrival\n",
    "        depth_threshold = 1.0  # 1 foot\n",
    "\n",
    "        # Find the time at which each column (grid element) first exceeds the depth threshold\n",
    "        for i in range(depth_data.shape[1]):  # iterate over each column (grid element)\n",
    "            exceedance_index = np.where(depth_data[:, i] >= depth_threshold)[0]\n",
    "            if exceedance_index.size > 0:\n",
    "                time_to_1_ft[i] = time_data[exceedance_index[0]]  # get the first time where depth exceeds\n",
    "\n",
    "        # Create or update the 'time_to_1_ft' dataset in the HDF5 file\n",
    "        if 'TIMDEP OUTPUT RESULTS/time_to_1_ft' in file:\n",
    "            del file['TIMDEP OUTPUT RESULTS/time_to_1_ft']  # remove existing dataset if it exists\n",
    "        file.create_dataset('TIMDEP OUTPUT RESULTS/time_to_1_ft', data=time_to_1_ft)\n",
    "\n",
    "        print(\"Dataset 'time_to_1_ft' has been created/updated.\")\n",
    "\n",
    "# Specify the path to your HDF5 file\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Run the function to add the floodwave arrival time dataset\n",
    "add_floodwave_arrival_table(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a074a-4ab2-4fae-9427-d3082e6cc0af",
   "metadata": {},
   "source": [
    "# ðŸ“Š HDF5 Time to 1 ft or m\n",
    "\n",
    "## Purpose\n",
    "Create a script to analyse an hdf5 file for the time to 1ft values and build them into a new table for the purpose of rasterizing the data.\n",
    "\n",
    "## Examples of Operations:\n",
    "- **Read HDF5 data**: The script accesses `depth values` data stored in the HDF5 file.\n",
    "- **Finds 1 ft**: Builds a new table with time that cell reaches 1ft. \n",
    "- **Data outup**: Writes the data to a file called time_to_1_ft.csv.\n",
    "\n",
    "## Instructions\n",
    "1. Ask ChatGPT to read the `hdf5` data and create a new table.\n",
    "2. Remember that the data is organized by column and row, where column 0 corresponds to grid element 1 and row 0 corresponds to time interval 1.\n",
    "3. Remember to tell ChatGPT the name and path of your file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440dfdd-8e3d-4766-926c-c9e655f0981f",
   "metadata": {},
   "source": [
    "## Example ChatGPT Query\n",
    "\n",
    "- **Objective**: Build a Python script to create a table that tracks the floodwave arrival time for each grid element to reach a depth of 1 foot.\n",
    "- **Data**:\n",
    "  - **Group**: `TIMDEP OUTPUT RESULTS/FLOW DEPTH`\n",
    "  - **Time Data**: Stored in a dataset named `Times`, structures as a single col of hours over intervals of 0.05 hours for a total of 10 hours.\n",
    "  - **Depth Data**: Stored in a dataset named `Values`, structured as rows as time intervals and columns as grid elements (1 to 8588), representing water depth in feet.\n",
    "- **New Table**: Create a dataset named `time_to_1_ft` within the same group to store the calculated time to reach 1 foot for each grid element.\n",
    "- **Conditions**: Not all grid elements will reach a depth of 1 foot. For those that do not, the time should be recorded as `0.0`.\n",
    "- **Dependencies**: Utilize the `h5py` library for HDF5 interaction.\n",
    "- **File Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Hdf5\\TIMDEPNC.HDF5`\n",
    "- **Request**: Can you provide a Python script to perform the calculations and update the HDF5 file as described?\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "The following code block is the result of this query. The bold text is not necessary in your queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cffd4-c9b6-4d19-92ed-9269987ced10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Define the file path\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as f:\n",
    "    # Access the group and datasets\n",
    "    group = f['TIMDEP OUTPUT RESULTS/FLOW DEPTH']\n",
    "    times = group['Times'][:]\n",
    "    values = group['Values'][:]\n",
    "\n",
    "    # Convert the values dataset to a NumPy array explicitly\n",
    "    depth_values = np.array(values)\n",
    "\n",
    "    # Vectorized approach to find the first time each grid reaches 1 foot of depth\n",
    "    # Mask of depths reaching or exceeding 1 foot\n",
    "    depth_mask = depth_values >= 1.0\n",
    "\n",
    "    # Use argmax to find the first true value in each column; if no true value, argmax returns 0\n",
    "    first_reach_indices = np.argmax(depth_mask, axis=0)\n",
    "\n",
    "    # Correct indices where no value reaches 1 foot (all False along the column)\n",
    "    no_reach_mask = ~depth_mask.any(axis=0)\n",
    "    first_reach_indices[no_reach_mask] = -1  # Set to -1 where no depth reaches 1 foot\n",
    "\n",
    "    # Create an array for time to reach 1 foot\n",
    "    time_to_1_ft = np.zeros(depth_values.shape[1], dtype=float)\n",
    "    time_to_1_ft[first_reach_indices != -1] = times[first_reach_indices[first_reach_indices != -1]]\n",
    "    time_to_1_ft[no_reach_mask] = 0.0  # Set time to 0.0 where no depth reaches 1 foot\n",
    "\n",
    "    # Create or update the dataset\n",
    "    if 'time_to_1_ft' in group:\n",
    "        del group['time_to_1_ft']\n",
    "    group.create_dataset('time_to_1_ft', data=time_to_1_ft)\n",
    "\n",
    "print(\"The dataset 'time_to_1_ft' has been updated with the arrival times.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda4b9c-6aab-4fb9-a5b8-2c3cefccc42c",
   "metadata": {},
   "source": [
    "# ðŸ“Š HDF5 Write Table to File\n",
    "\n",
    "## Purpose\n",
    "Create a script to analyse an hdf5 file for the time to 1ft values and build them into a new table for the purpose of rasterizing the data.\n",
    "\n",
    "## Examples of Operations:\n",
    "- **Read HDF5 data**: The script accesses `time_to_1_ft` data stored in the HDF5 file.\n",
    "- **Finds X Y**: Finds X and Y centroid coordinate from the hdf5 data. \n",
    "- **Data output**: Writes the data to a file called time_to_1_ft.csv in a format that FLO-2D Rasterizor can read.\n",
    "\n",
    "## Instructions\n",
    "1. Ask ChatGPT to read the `hdf5` data and create Join the data.\n",
    "2. Remember that the data is organized by column and row, where column 0 corresponds to grid element 1 and row 0 corresponds to time interval 1.\n",
    "3. The X and Y data is in a 1D col table.\n",
    "4. Output the data as GE X Y VAL space delimited.\n",
    "5. Remember to tell ChatGPT the name and path of your file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c963e7-e34a-4d65-a2d4-76ff90a85ac0",
   "metadata": {},
   "source": [
    "## Example ChatGPT Query\n",
    "\n",
    "- **Objective**: Create a Python script to export data from an HDF5 file to a text file.\n",
    "- **Data**: The script should export the grid element number (GE), X and Y coordinates (centroids), and the time to reach 1 foot of flow depth (VAL).\n",
    "- **Structure**: Ensure the data is organized by grid element number, with columns corresponding to GE, X, Y, and VAL. GE should start at 1 for the first grid element.\n",
    "- **Output Format**: Save the output in a text file named `time_to_1_ft.out` as space-delimited data.\n",
    "- **Dependencies**: Use `h5py` and `numpy` for handling the HDF5 file and numerical operations.\n",
    "- **File Paths**: Include variables to set file paths for reading the input and writing the output.\n",
    "- **Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Hdf5\\TIMDEPNC.HDF5`\n",
    "- **Request**: Can you provide a Python script to export the data to the specified output file using the details provided?\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "```\n",
    "Group: TIMDEP OUTPUT RESULTS/FLOW DEPTH\n",
    "Dataset: TIMDEP OUTPUT RESULTS/FLOW DEPTH/Maxs - Shape: (200,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/FLOW DEPTH/Mins - Shape: (200,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times - Shape: (200,), Dtype: float64\n",
    "Dataset: TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values - Shape: (200, 8588), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/FLOW DEPTH/time_to_1_ft - Shape: (8588,), Dtype: float64\n",
    "\n",
    "Group: TIMDEP OUTPUT RESULTS/X-Coordinate\n",
    "Dataset: TIMDEP OUTPUT RESULTS/X-Coordinate/Maxs - Shape: (1,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/X-Coordinate/Mins - Shape: (1,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/X-Coordinate/Times - Shape: (1,), Dtype: float64\n",
    "Dataset: TIMDEP OUTPUT RESULTS/X-Coordinate/Values - Shape: (1, 8588), Dtype: float32\n",
    "\n",
    "Group: TIMDEP OUTPUT RESULTS/Y-Coordinate\n",
    "Dataset: TIMDEP OUTPUT RESULTS/Y-Coordinate/Maxs - Shape: (1,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/Y-Coordinate/Mins - Shape: (1,), Dtype: float32\n",
    "Dataset: TIMDEP OUTPUT RESULTS/Y-Coordinate/Times - Shape: (1,), Dtype: float64\n",
    "Dataset: TIMDEP OUTPUT RESULTS/Y-Coordinate/Values - Shape: (1, 8588), Dtype: float32\n",
    "```\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "\n",
    "Here is the Python script to perform the data export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8adef-d91c-469a-9020-0dbe1331ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the HDF5 file\n",
    "hdf5_file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "output_file_path = base_path / 'Data' / 'Hdf5' / 'time_to_1_ft.out'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_path, 'r') as file:\n",
    "    # Load the necessary datasets\n",
    "    x_coords = file['TIMDEP OUTPUT RESULTS/X-Coordinate/Values'][0]\n",
    "    y_coords = file['TIMDEP OUTPUT RESULTS/Y-Coordinate/Values'][0]\n",
    "    time_to_1_ft = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/time_to_1_ft'][:]\n",
    "    \n",
    "    # Prepare the data for output\n",
    "    grid_elements = np.arange(1, len(time_to_1_ft) + 1)\n",
    "    data = np.column_stack((grid_elements, x_coords, y_coords, time_to_1_ft))\n",
    "    \n",
    "    # Save the data to a text file\n",
    "    np.savetxt(output_file_path, data, fmt='%d %.6f %.6f %.6f', delimiter=' ', header='GE X Y VAL', comments='')\n",
    "\n",
    "print(f'Data successfully exported to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d18aa8-1a21-4989-afde-64fe3ae081f7",
   "metadata": {},
   "source": [
    "# ðŸ“Š HDF5 Plot Data\n",
    "\n",
    "## Purpose\n",
    "This script reads `DepXVel` data from an HDF5 file and plots it over time for a specific grid element. The plot helps visualize how shear stress (or depth * velocity) changes throughout the simulation.\n",
    "\n",
    "## Examples of Operations:\n",
    "- **Read HDF5 data**: The script accesses `DepXVel` data stored in the HDF5 file.\n",
    "- **Plot data over time**: It generates a time series plot for a specific grid element.\n",
    "- **Select the grid element**: You can specify the grid element (column) for which you want to plot the depth * velocity.\n",
    "\n",
    "## Instructions\n",
    "1. Ask ChatGPT to read the `DepXVel` data and plot it for a specific grid element number.\n",
    "2. Remember that the data is organized by column and row, where column 0 corresponds to grid element 1.\n",
    "3. Ask ChatGPT to let you input the grid element number you want to plot.\n",
    "4. Remember to tell ChatGPT the name and path of your file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced250ae-2350-4979-b74b-a3b4f7ffaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_individual_data(hdf5_path, grid_element):\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(hdf5_path, 'r') as file:\n",
    "        # Access the Times dataset to get the time steps\n",
    "        times = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times'][:]\n",
    "        \n",
    "        # Adjust grid_element index for 0-based indexing in Python (HDF5 data is 1-based)\n",
    "        index = grid_element - 1\n",
    "\n",
    "        # Access the Values dataset for depth\n",
    "        depth_values = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values'][:, index]\n",
    "\n",
    "        # Access the velocity and squared velocity datasets\n",
    "        dep_x_vel = file['TIMDEP OUTPUT RESULTS/dep_x_vel'][:, index]\n",
    "        dep_x_sqvel = file['TIMDEP OUTPUT RESULTS/dep_x_sqvel'][:, index]\n",
    "        \n",
    "        # Access the maximum velocity dataset\n",
    "        max_vel_values = file['TIMDEP OUTPUT RESULTS/MAX VEL/Values'][:, index]\n",
    "\n",
    "        # Plot Depth\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(times, depth_values, label='Depth (ft)', color='tab:green')\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Depth (ft)')\n",
    "        plt.title(f'Depth for Grid Element: {grid_element}')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot Velocity\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(times, max_vel_values, label='Maximum Velocity (ft/s)', color='tab:purple')\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Velocity (ft/s)')\n",
    "        plt.title(f'Velocity for Grid Element: {grid_element}')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot Depth * Velocity\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(times, dep_x_vel, label='Depth * Velocity (ft^2/s)', color='tab:red')\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Dep * Vel (ft^2/s)')\n",
    "        plt.title(f'Depth Times Velocity for Grid Element: {grid_element}')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot Depth * Squared Velocity\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(times, dep_x_sqvel, label='Depth * Squared Velocity (ft^2/s)', color='tab:blue')\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Depth * Squared Velocity (ft^3/s^2)')\n",
    "        plt.title(f'Depth Times Velocity Squared for Grid Element: {grid_element}')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Specify the path to the HDF5 file and the grid element to plot\n",
    "hdf5_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "grid_element = 5021\n",
    "\n",
    "# Call the function\n",
    "plot_individual_data(hdf5_path, grid_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a28cd-e392-4763-8827-3e21594997bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the HDF5 file\n",
    "file_path = base_path / 'Data' / 'Hdf5' / 'TIMDEPNC.HDF5'\n",
    "\n",
    "# Function to plot data with specified color\n",
    "def plot_data(times, data, title, x_label, y_label, color):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(times, data, color=color)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # Extract data for grid element 5021 (adjust for zero-based indexing in Python)\n",
    "    grid_index = 5021 - 1\n",
    "    \n",
    "    # Load the time data\n",
    "    times = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times'][:]\n",
    "    \n",
    "    # Load the depth data for grid element 5021\n",
    "    depths = file['TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values'][:, grid_index]\n",
    "    plot_data(times, depths, 'Depth vs Time', 'Time (hours)', 'Depth (ft)', 'blue')\n",
    "    \n",
    "    # Load the velocity data for grid element 5021\n",
    "    velocities = file['TIMDEP OUTPUT RESULTS/MAX VEL/Values'][:, grid_index]\n",
    "    plot_data(times, velocities, 'Velocity vs Time', 'Time (hours)', 'Velocity (ft/s)', 'green')\n",
    "    \n",
    "    # Load the dep_x_vel data for grid element 5021\n",
    "    dep_x_vel = file['TIMDEP OUTPUT RESULTS/dep_x_vel'][:, grid_index]\n",
    "    plot_data(times, dep_x_vel, 'Depth x Velocity vs Time', 'Time (hours)', 'Depth x Velocity', 'red')\n",
    "    \n",
    "    # Load the dep_x_sqvel data for grid element 5021\n",
    "    dep_x_sqvel = file['TIMDEP OUTPUT RESULTS/dep_x_sqvel'][:, grid_index]\n",
    "    plot_data(times, dep_x_sqvel, 'Depth x Velocity^2 vs Time', 'Time (hours)', 'Depth x Velocity^2', 'purple')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "flo2d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
