{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c2f026",
   "metadata": {},
   "source": [
    "# Green & Ampt Infiltration Processor\n",
    "\n",
    "The FLO-2D model includes the Green-Ampt infiltration method as one of its core infiltration engines. This approach is used in hydrologic modeling because it effectively captures transmission losses as water infiltrates into the soil.\n",
    "\n",
    "In the FLO-2D model, rainfall is distributed to the computational grid, where it infiltrates into the soil until reaching the saturation depth or fill volume. This continuous process accounts for the dynamic movement of water through the watershed as flood routing progresses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c05039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically set base path to the project directory where the notebook is running\n",
    "from pathlib import Path\n",
    "\n",
    "# This gets the directory where the current notebook is located\n",
    "base_path = Path.cwd()\n",
    "\n",
    "print(f\"ðŸ“‚ Base path automatically set to: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57286347",
   "metadata": {},
   "source": [
    "# Find the fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print the fields of vector files in the project directory. This script prints the \n",
    "fields of shapefiles and GeoPackage files in the specified directory.  The resulting \n",
    "list can be used to fill the fields list in the next processor which will write a \n",
    "raster file for each field.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from osgeo import ogr, gdal\n",
    "import shapefile  # pyshp\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress GDAL exception warnings\n",
    "ogr.UseExceptions()\n",
    "gdal.UseExceptions()\n",
    "\n",
    "\n",
    "# File paths\n",
    "soil_shapefile = base_path / 'Data' / 'Infiltration' / 'Soil 2023.shp'\n",
    "landuse_shapefile = base_path / 'Data' / 'Infiltration' / 'Land Use 2018.shp'\n",
    "grid_layer_path = base_path / 'Data' / 'GeoPackage' / 'selfhelp.gpkg'\n",
    "\n",
    "def print_fields(filepath):\n",
    "    if filepath.suffix == '.shp':\n",
    "        # Use pyshp for shapefiles\n",
    "        sf = shapefile.Reader(str(filepath))\n",
    "        fields = [f[0] for f in sf.fields[1:]]  # Skip deletion flag\n",
    "        sf.close()\n",
    "    elif filepath.suffix == '.gpkg':\n",
    "        # Use ogr for GeoPackage\n",
    "        ds = ogr.Open(str(filepath))\n",
    "        layer = ds.GetLayer()\n",
    "        fields = [field.name for field in layer.schema]\n",
    "        ds = None\n",
    "    else:\n",
    "        print(f\"âš ï¸ Unsupported file type: {filepath}\")\n",
    "        return\n",
    "\n",
    "    # Print the fields\n",
    "    print(f\"\\nFields in {filepath.name}:\")\n",
    "    for field in fields:\n",
    "        print(f\" - {field}\")\n",
    "\n",
    "# Print the fields for each vector file\n",
    "print_fields(soil_shapefile)\n",
    "print_fields(landuse_shapefile)\n",
    "print_fields(grid_layer_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2664fd3",
   "metadata": {},
   "source": [
    "# Rasterize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal, ogr\n",
    "import shapefile  # pyshp\n",
    "import tempfile\n",
    "\n",
    "# Define input paths\n",
    "soil_shapefile = base_path / 'Data' / 'Infiltration' / 'Soil 2023.shp'\n",
    "landuse_shapefile = base_path / 'Data' / 'Infiltration' / 'Land Use 2018.shp'\n",
    "grid_layer_path = base_path / 'Data' / 'GeoPackage' / 'selfhelp.gpkg'\n",
    "output_folder = base_path / 'Data' / 'Infiltration' / 'Rasters'\n",
    "\n",
    "# Fields to rasterize.  Make sure these fields are in the results printed by the previous cell.\n",
    "soil_fields = ['hydc', 'soil_depth', 'psif', 'dthetad', 'dthetan', 'dthetaw']\n",
    "landuse_fields = ['IA', 'RTIMP', 'VC', 'InitSat']\n",
    "\n",
    "# EPSG code for NAD83 Central AZ\n",
    "target_epsg = 2223\n",
    "\n",
    "import shapefile\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def preprocess_sat_field(shapefile_path, field_name=\"InitSat\"):\n",
    "    \"\"\"\n",
    "    Preprocess the InitSat field in the shapefile to convert categorical values to numeric.  \n",
    "    Converts:\n",
    "    - \"wet\" to 0\n",
    "    - \"normal\" to 1\n",
    "    - \"dry\" to 2\n",
    "    - Anything else to -1 (unknown)\n",
    "    \"\"\"\n",
    "    # Load the shapefile\n",
    "    reader = shapefile.Reader(shapefile_path)\n",
    "    fields = reader.fields[1:]  # skip DeletionFlag\n",
    "    field_names = [f[0] for f in fields]\n",
    "\n",
    "    if field_name not in field_names:\n",
    "        raise ValueError(f\"Field '{field_name}' not found in {shapefile_path}\")\n",
    "\n",
    "    # Find the index of the InitSat field\n",
    "    sat_index = field_names.index(field_name)\n",
    "\n",
    "    # Create a temporary directory for the processed shapefile\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    print(f\"Temp directory for Sat processing: {temp_dir}\")\n",
    "    temp_shp = os.path.join(temp_dir, \"processed.shp\")\n",
    "\n",
    "    # Create the new shapefile with the updated InitSat field\n",
    "    writer = shapefile.Writer(temp_shp)\n",
    "    for field in fields:\n",
    "        if field[0] == field_name:\n",
    "            writer.field(field_name, 'N', decimal=0)\n",
    "        else:\n",
    "            writer.field(*field)\n",
    "\n",
    "    # Process each record\n",
    "    record_count = 0\n",
    "    for sr in reader.shapeRecords():\n",
    "        rec = list(sr.record)\n",
    "        val = str(rec[sat_index]).strip()\n",
    "        if val == \"wet\":\n",
    "            rec[sat_index] = 0\n",
    "        elif val == \"normal\":\n",
    "            rec[sat_index] = 1\n",
    "        elif val == \"dry\":\n",
    "            rec[sat_index] = 2\n",
    "        else:\n",
    "            rec[sat_index] = -1  # unknown category\n",
    "\n",
    "        writer.shape(sr.shape)\n",
    "        writer.record(*rec)\n",
    "        record_count += 1\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"Processed {record_count} records to {temp_shp}\")\n",
    "    return temp_shp\n",
    "\n",
    "\n",
    "# Rasterization properties calculated from the grid layer.\n",
    "def rasterize_field(input_vector, field, reference_layer, output_path):\n",
    "    \"\"\"\"\n",
    "    Rasterizes a field from a vector file to a raster file using the specified reference layer.\n",
    "    \"\"\"\n",
    "\n",
    "    grid_ds = gdal.OpenEx(reference_layer, gdal.OF_VECTOR)\n",
    "    grid_layer = grid_ds.GetLayer()\n",
    "    xmin, xmax, ymin, ymax = grid_layer.GetExtent()\n",
    "    xres = 30\n",
    "    yres = 30\n",
    "    cols = int((xmax - xmin) / xres)\n",
    "    rows = int((ymax - ymin) / yres)\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_raster = driver.Create(output_path, cols, rows, 1, gdal.GDT_Float32)\n",
    "    out_raster.SetGeoTransform((xmin, xres, 0, ymax, 0, -yres))\n",
    "\n",
    "    srs = ogr.osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(target_epsg)\n",
    "    out_raster.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "    vector_ds = ogr.Open(input_vector)\n",
    "    vector_layer = vector_ds.GetLayer()\n",
    "\n",
    "    gdal.RasterizeLayer(out_raster, [1], vector_layer, options=[\n",
    "        f\"ATTRIBUTE={field}\",\n",
    "        \"ALL_TOUCHED=TRUE\"\n",
    "    ])\n",
    "    print(f\"Raster saved: {output_path}\")\n",
    "\n",
    "# Make sure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Rasterize Soil fields\n",
    "for field in soil_fields:\n",
    "    out_path = os.path.join(output_folder, f\"{field}.tif\")\n",
    "    rasterize_field(soil_shapefile, field, grid_layer_path, out_path)\n",
    "\n",
    "# Rasterize Land Use fields\n",
    "for field in landuse_fields:\n",
    "    input_path = landuse_shapefile\n",
    "\n",
    "    # Preprocess InitSat specifically\n",
    "    if field == \"InitSat\":\n",
    "        print(f\"Preprocessing {field} for numeric conversion...\")\n",
    "        # Corrected shapefile path\n",
    "        input_path = preprocess_sat_field(str(landuse_shapefile), field)\n",
    "\n",
    "    out_path = os.path.join(output_folder, f\"{field}.tif\")\n",
    "    print(f\"Rasterizing {field} from {input_path} to {out_path}\")\n",
    "    rasterize_field(input_path, field, grid_layer_path, out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c60b9f",
   "metadata": {},
   "source": [
    "# Process GeoPackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6393734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fields in the layer: ['col', 'row', 'n_value', 'elevation', 'water_elevation', 'flow_depth']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Field 'fid' not found in the layer. Available fields: ['col', 'row', 'n_value', 'elevation', 'water_elevation', 'flow_depth']. Note: 'fid' might be a special field and not listed explicitly.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m actual_field_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_field_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m field_names:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_field_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in the layer. Available fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Note: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m might be a special field and not listed explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Extract centroids from each grid feature\u001b[39;00m\n\u001b[0;32m     38\u001b[0m centroids \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Field 'fid' not found in the layer. Available fields: ['col', 'row', 'n_value', 'elevation', 'water_elevation', 'flow_depth']. Note: 'fid' might be a special field and not listed explicitly.\""
     ]
    }
   ],
   "source": [
    "# Green-Ampt Raster Sampler\n",
    "# \n",
    "# This script extracts centroid coordinates from a grid layer in a GeoPackage, samples raster values at those centroids, \n",
    "# and saves the results to a new GeoPackage layer. It is designed for large datasets and avoids dependencies on rasterio or geopandas.\n",
    "#\n",
    "# Author: ChatGPT\n",
    "\n",
    "import os\n",
    "from osgeo import ogr, gdal, osr\n",
    "from pathlib import Path\n",
    "\n",
    "# Set paths and configuration\n",
    "# Paths to input files and output location\n",
    "base_path = Path(\"C:/Users/Karen/VS Code Projects/ASFPM-LLM-Data-Management-Workshop\")\n",
    "grid_path = base_path / 'Data' / 'GeoPackage' / 'selfhelp.gpkg'\n",
    "raster_folder = base_path / 'Data' / 'Infiltration' / 'Rasters'\n",
    "grid_layer_name = \"grid\"\n",
    "output_gpkg = grid_path\n",
    "output_layer_name = \"green_ampt_sampled\"\n",
    "epsg = 2223  # NAD83 / Arizona Central (ft)\n",
    "\n",
    "# Open the grid GeoPackage and get the grid layer\n",
    "# This loads the vector data so we can extract centroids\n",
    "grid_ds = gdal.OpenEx(str(grid_path), gdal.OF_VECTOR)\n",
    "grid_layer = grid_ds.GetLayerByName(grid_layer_name)\n",
    "\n",
    "# Verify the field names in the grid layer\n",
    "layer_defn = grid_layer.GetLayerDefn()\n",
    "field_names = [layer_defn.GetFieldDefn(i).GetName() for i in range(layer_defn.GetFieldCount())]\n",
    "print(f\"Available fields in the layer: {field_names}\")\n",
    "\n",
    "# Use the known field name 'fid' if it exists, otherwise raise an error\n",
    "actual_field_name = 'fid'\n",
    "if actual_field_name not in field_names:\n",
    "    raise KeyError(f\"Field '{actual_field_name}' not found in the layer. Available fields: {field_names}. Note: 'fid' might be a special field and not listed explicitly.\")\n",
    "\n",
    "# Extract centroids from each grid feature\n",
    "centroids = []\n",
    "grid_layer.ResetReading()\n",
    "for feat in grid_layer:\n",
    "    # Get the centroid of each feature\n",
    "    geom = feat.GetGeometryRef().Centroid()\n",
    "    x = geom.GetX()\n",
    "    y = geom.GetY()\n",
    "    # Use the known field name 'fid'\n",
    "    grid_id = feat.GetField(actual_field_name)\n",
    "    centroids.append({\"grid_id\": grid_id, \"x\": x, \"y\": y})\n",
    "\n",
    "# Close the grid data source to free up memory\n",
    "grid_ds = None\n",
    "\n",
    "# Create the output GeoPackage layer\n",
    "# This layer will store the sampled points and their raster values\n",
    "driver = ogr.GetDriverByName(\"GPKG\")\n",
    "if os.path.exists(output_gpkg):\n",
    "    ds_out = driver.Open(str(output_gpkg), update=1)\n",
    "else:\n",
    "    ds_out = driver.CreateDataSource(str(output_gpkg))\n",
    "\n",
    "# Remove existing layer if it exists (to avoid duplicate layers)\n",
    "if ds_out.GetLayerByName(output_layer_name):\n",
    "    ds_out.DeleteLayer(output_layer_name)\n",
    "\n",
    "# Create a spatial reference object for the new layer\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(epsg)\n",
    "out_layer = ds_out.CreateLayer(output_layer_name, srs, ogr.wkbPoint)\n",
    "\n",
    "# Add basic coordinate and ID fields\n",
    "out_layer.CreateField(ogr.FieldDefn(\"grid_id\", ogr.OFTInteger))\n",
    "out_layer.CreateField(ogr.FieldDefn(\"x\", ogr.OFTReal))\n",
    "out_layer.CreateField(ogr.FieldDefn(\"y\", ogr.OFTReal))\n",
    "\n",
    "# Add fields for each raster (limited to 10 characters for GPKG compatibility)\n",
    "raster_files = [f for f in os.listdir(raster_folder) if f.endswith(\".tif\")]\n",
    "for raster_file in raster_files:\n",
    "    field_name = os.path.splitext(raster_file)[0][:10]  # Limit to 10 characters for GPKG compatibility\n",
    "    out_layer.CreateField(ogr.FieldDefn(field_name, ogr.OFTReal))\n",
    "\n",
    "# Sample raster values at each centroid\n",
    "for center in centroids:\n",
    "    x, y = center[\"x\"], center[\"y\"]\n",
    "\n",
    "    # Create the point feature\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(x, y)\n",
    "\n",
    "    feat = ogr.Feature(out_layer.GetLayerDefn())\n",
    "    feat.SetField(\"grid_id\", int(center[\"grid_id\"]))\n",
    "    feat.SetField(\"x\", x)\n",
    "    feat.SetField(\"y\", y)\n",
    "    feat.SetGeometry(pt)\n",
    "\n",
    "    # Sample each raster at this point\n",
    "    for raster_file in raster_files:\n",
    "        raster_path = raster_folder / raster_file\n",
    "        raster_name = os.path.splitext(raster_file)[0][:10]  # Use the truncated name as the field name\n",
    "\n",
    "        # Open the raster and get the transform\n",
    "        ds = gdal.Open(str(raster_path))\n",
    "        gt = ds.GetGeoTransform()\n",
    "        band = ds.GetRasterBand(1)\n",
    "\n",
    "        # Convert point coordinates to pixel coordinates\n",
    "        px = int((x - gt[0]) / gt[1])\n",
    "        py = int((y - gt[3]) / gt[5])\n",
    "\n",
    "        try:\n",
    "            # Read the single pixel value\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            feat.SetField(raster_name, value)\n",
    "        except Exception as e:\n",
    "            # Use None for out-of-bounds or nodata errors\n",
    "            feat.SetField(raster_name, None)\n",
    "\n",
    "        ds = None  # Close the raster\n",
    "\n",
    "    # Create the feature in the output layer\n",
    "    out_layer.CreateFeature(feat)\n",
    "    feat = None  # Clean up\n",
    "\n",
    "ds_out = None  # Close the output GeoPackage\n",
    "print(f\"âœ… Sample table saved to layer '{output_layer_name}' in {output_gpkg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flo2d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
