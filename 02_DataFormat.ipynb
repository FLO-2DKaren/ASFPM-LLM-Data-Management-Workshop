{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cbd4f7-e3f7-4973-b9ea-c658d34187b2",
   "metadata": {
    "id": "90cbd4f7-e3f7-4973-b9ea-c658d34187b2"
   },
   "source": [
    "<h1 style=\"color:blue;\">Data Conversion</h1>\n",
    "\n",
    "## Purpose\n",
    "Simplify files so that Python can read and parse data easily. Get scripts to process data into different filetypes, and number formats. Convert the time data to a date time that can syncronize a hydrograph input to a date time input.\n",
    "\n",
    "## View Video\n",
    "The video for this section is in sharefile `04_01 ASCII Data Conversion.mp4`.\n",
    "\n",
    "## Ask ChatGPT for a Python Script\n",
    "\n",
    "- **Objective**: I need a Python script to parse a `hydrostruct.out` file into a more readable csv file.\n",
    "- **Data**: The script should read structure name, time, inflow, and outflow from each section.\n",
    "- **Skip Lines**: The first dataset starts with 'THE MAXIMUM', skip empty lines.\n",
    "- **Output Format**: Save the output in a CSV file named `hydrostruct_simple.csv` with columns for the hydrograph name, time, inflow, and outflow.\n",
    "- **Dependencies**: Use Pandas.\n",
    "- **File Paths**: Include variables to set file paths for reading the input and writing the output.\n",
    "- **Path**: Update this path. `C:\\Users\\User\\Chat GPT Workshop\\Data\\Ascii`\n",
    "- **Request**: Can you help me write this Python script using the details provided?\n",
    "\n",
    "### ðŸ”½ Code Block\n",
    "***The following cell is an example of what ChatGPT can build.  You can run this code with the dashboard controls or by \"shift-enter\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3e2a22-561d-4aee-ae76-b58634fa9b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dates:\n",
      "2025-03-01\n",
      "2025-03-02\n",
      "2025-03-03\n",
      "\n",
      "Formatted dates:\n",
      "March 01, 2025\n",
      "March 02, 2025\n",
      "March 03, 2025\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a list of dates\n",
    "dates = [datetime.date(2025, 3, 1), datetime.date(2025, 3, 2), datetime.date(2025, 3, 3)]\n",
    "\n",
    "# Print the original dates\n",
    "print(\"Original dates:\")\n",
    "for date in dates:\n",
    "    print(date)\n",
    "\n",
    "# Convert dates to different formats\n",
    "formatted_dates = []\n",
    "for date in dates:\n",
    "    # Format the date as \"Month day, Year\"\n",
    "    formatted_date = date.strftime(\"%B %d, %Y\")\n",
    "    formatted_dates.append(formatted_date)\n",
    "\n",
    "# Print the formatted dates\n",
    "print(\"\\nFormatted dates:\")\n",
    "for date in formatted_dates:\n",
    "    print(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf8dbe-cdb5-4fb2-9057-f624d9819953",
   "metadata": {},
   "source": [
    "## Example ChatGPT Query\n",
    "\n",
    "- **Objective**: I need a Python script to parse a `hydrostruct.out` file into a more readable csv file.\n",
    "- **Data**: The script should read structure name, time, inflow, and outflow from each section.\n",
    "- **Skip Lines**: The first dataset starts with 'THE MAXIMUM', skip empty lines.\n",
    "- **Output Format**: Save the output in a CSV file named `hydrostruct_simple.csv` with columns for the hydrograph name, time, inflow, and outflow.\n",
    "- **Dependencies**: Use Pandas.\n",
    "- **File Paths**: Include variables to set file paths for reading the input and writing the output.\n",
    "- **Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Ascii`\n",
    "- **Request**: Can you write a Python to write the data to the output file using the details provided?\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "\n",
    "The following code block is the result of this query. The bold text is not necessary in your queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b07df5c-d47c-4c94-82b8-6dbc7ce40a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Ascii\\hydrostruct_simple.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_hydrostruct(file_path, output_path):\n",
    "    # Initialize data storage\n",
    "    data = {\n",
    "        'Structure_Name': [],\n",
    "        'Time_hrs': [],\n",
    "        'Inflow_cfs': [],\n",
    "        'Outflow_cfs': []\n",
    "    }\n",
    "\n",
    "    # Open the file and read lines\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Clean and filter out unnecessary lines\n",
    "    lines = [line.strip() for line in lines if line.strip() and not line.strip().startswith('INFLOW')]\n",
    "\n",
    "    # Process lines\n",
    "    current_structure = None\n",
    "    for line in lines:\n",
    "        if line.startswith('THE MAXIMUM'):\n",
    "            current_structure = line.split(':')[1].split('STRUCTURE')[0].strip()\n",
    "        elif line[0].isdigit():\n",
    "            time, inflow, outflow = line.split()\n",
    "            data['Structure_Name'].append(current_structure)\n",
    "            data['Time_hrs'].append(float(time))\n",
    "            data['Inflow_cfs'].append(float(inflow))\n",
    "            data['Outflow_cfs'].append(float(outflow))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Data written to {output_path}\")\n",
    "\n",
    "# File paths\n",
    "input_path = 'C:\\\\Users\\\\Karen\\\\Chat GPT Workshop\\\\Data\\\\Ascii\\\\HYDROSTRUCT.OUT'\n",
    "output_path = 'C:\\\\Users\\\\Karen\\\\Chat GPT Workshop\\\\Data\\\\Ascii\\\\hydrostruct_simple.csv'\n",
    "\n",
    "# Run the function\n",
    "parse_hydrostruct(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85a5ed-450c-4faa-9c8f-68ef38c46325",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Date Time Conversion</h1>\n",
    "\n",
    "## Purpose\n",
    "Convert the hydrograph time data with a date time format.\n",
    "\n",
    "## View Video\n",
    "The video for this section is in sharefile `04_02 Date Time Conversion.mp4`.\n",
    "\n",
    "## Ask ChatGPT for a Python Script\n",
    "\n",
    "- **Objective**: I need a Python script to replace the time (hrs) in `hydrostruct_simple.csv` file into a different date time format.\n",
    "- **Data**: Time is in col2, new format `mm/dd/yyyy hh:mm:ss Start time = 03/13/2025 00:00:00`\n",
    "- **Add Zero Time**: The datasets are missing zero time.  Can you one row for struct_name 0.0 time, 0.0 dicharge, 0.0 discharge to each dataset.\n",
    "- **Output Format**: Save the output in a CSV file named `hydrostruct_datetime.csv` with columns for the StructName, datetime, inflow_cfs, and outflow_cfs.\n",
    "- **Dependencies**: Use Pandas.\n",
    "- **File Paths**: Include variables to set file paths for reading the input and writing the output.\n",
    "- **Path**: Update this path. r`C:\\Users\\User\\Chat GPT Workshop\\Data\\Ascii`\n",
    "- **Request**: Can you help me write this Python script using the details provided?\n",
    "\n",
    "### ðŸ”½ Code Block\n",
    "***The following cell is an example of what ChatGPT can build.  You can run this code with the dashboard controls or by \"shift-enter\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d22fd48e-7d67-41f3-9168-3eb9cf81d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been processed and saved to C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Ascii\\hydrostruct_datetime.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Ascii\\hydrostruct_simple.csv'\n",
    "output_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Ascii\\hydrostruct_datetime.csv'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Start time for the dataset\n",
    "start_time = datetime.strptime('03/13/2025 00:00:00', '%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# Calculate the datetime for each time entry\n",
    "df['datetime'] = df['Time_hrs'].apply(lambda x: start_time + timedelta(hours=x))\n",
    "\n",
    "# Find unique structure names\n",
    "unique_structures = df['Structure_Name'].unique()\n",
    "\n",
    "# Create a DataFrame for zero time entries\n",
    "zero_time_rows = []\n",
    "for struct in unique_structures:\n",
    "    zero_time_data = {'Structure_Name': struct, 'Time_hrs': 0.0, 'Inflow_cfs': 0.0, 'Outflow_cfs': 0.0, \n",
    "                      'datetime': start_time}\n",
    "    zero_time_rows.append(zero_time_data)\n",
    "\n",
    "zero_time_df = pd.DataFrame(zero_time_rows)\n",
    "\n",
    "# Append zero time rows to the original DataFrame\n",
    "df = pd.concat([zero_time_df, df], ignore_index=True)\n",
    "\n",
    "# Reorder DataFrame by Structure_Name and datetime\n",
    "df = df.sort_values(by=['Structure_Name', 'datetime'])\n",
    "\n",
    "# Select and reorder the final columns\n",
    "final_df = df[['Structure_Name', 'datetime', 'Inflow_cfs', 'Outflow_cfs']]\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Data has been processed and saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f014f51d-d912-450a-867e-eda201e871dd",
   "metadata": {
    "id": "f014f51d-d912-450a-867e-eda201e871dd"
   },
   "source": [
    "<h1 style=\"color:blue;\">Numerical Precision and Float Variables</h1>\n",
    "\n",
    "## Purpose\n",
    "Precision is crucial in 2D modeling and large data operations because it affects the accuracy of calculations and the reliability of results. Inadequate precision can lead to errors that may impact analyses and simulations, making it vital to understand how to manage numerical data effectively.\n",
    "\n",
    "## View Video\n",
    "The video for this section is in sharefile `04_03 Numerical Precision.mp4`.\n",
    "\n",
    "## Examples\n",
    "Here are some common operations involving float variables:\n",
    "\n",
    "- **Calculate the area of every grid element in a mesh**:\n",
    "- **Convert a float to an integer**:\n",
    "- **Round a float to an integer**:\n",
    "\n",
    "## Instructions\n",
    "1. **Ask ChatGPT to define floats and integers.** Understand how a float differs from a real number in terms of representation and precision.\n",
    "\n",
    "2. **Request ChatGPT to build a list of float values.** This will help you see the diversity of float representations.\n",
    "\n",
    "3. **Ask ChatGPT to create a script to convert the float values to integers.** This practice will illustrate the conversion process and its implications.\n",
    "\n",
    "4. **Request a script to sort the data from high to low.** Sorting allows you to analyze data trends and patterns effectively.\n",
    "\n",
    "By mastering numerical precision and float variables, you can enhance the accuracy and reliability of your data analysis in various applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e500fe93-bf9e-4971-a41e-4684942b20da",
   "metadata": {
    "id": "e500fe93-bf9e-4971-a41e-4684942b20da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Float Values</th>\n",
       "      <th>Integer Values</th>\n",
       "      <th>Rounded Integers</th>\n",
       "      <th>Rounded to 4 Decimals</th>\n",
       "      <th>Reconverted Floats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.344402</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59.3444</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.151854</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74.1519</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.145940</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64.1459</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.994603</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>58.9946</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.205277</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48.2053</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67.984576</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>67.9846</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.445262</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49.4453</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>89.867797</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>89.8678</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96.265986</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96.2660</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44.626295</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>44.6263</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80.963528</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>80.9635</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57.571648</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>57.5716</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61.055966</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61.0560</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92.878101</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>92.8781</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.822209</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16.8222</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18.254508</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18.2545</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.299437</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12.2994</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84.603166</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84.6032</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79.755951</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>79.7560</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87.931081</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>87.9311</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Float Values  Integer Values  Rounded Integers  Rounded to 4 Decimals  \\\n",
       "0      59.344402              59                59                59.3444   \n",
       "1      74.151854              74                74                74.1519   \n",
       "2      64.145940              64                64                64.1459   \n",
       "3      58.994603              58                59                58.9946   \n",
       "4      48.205277              48                48                48.2053   \n",
       "5      67.984576              67                68                67.9846   \n",
       "6      49.445262              49                49                49.4453   \n",
       "7      89.867797              89                90                89.8678   \n",
       "8      96.265986              96                96                96.2660   \n",
       "9      44.626295              44                45                44.6263   \n",
       "10     80.963528              80                81                80.9635   \n",
       "11     57.571648              57                58                57.5716   \n",
       "12     61.055966              61                61                61.0560   \n",
       "13     92.878101              92                93                92.8781   \n",
       "14     16.822209              16                17                16.8222   \n",
       "15     18.254508              18                18                18.2545   \n",
       "16     12.299437              12                12                12.2994   \n",
       "17     84.603166              84                85                84.6032   \n",
       "18     79.755951              79                80                79.7560   \n",
       "19     87.931081              87                88                87.9311   \n",
       "\n",
       "    Reconverted Floats  \n",
       "0                 59.0  \n",
       "1                 74.0  \n",
       "2                 64.0  \n",
       "3                 58.0  \n",
       "4                 48.0  \n",
       "5                 67.0  \n",
       "6                 49.0  \n",
       "7                 89.0  \n",
       "8                 96.0  \n",
       "9                 44.0  \n",
       "10                80.0  \n",
       "11                57.0  \n",
       "12                61.0  \n",
       "13                92.0  \n",
       "14                16.0  \n",
       "15                18.0  \n",
       "16                12.0  \n",
       "17                84.0  \n",
       "18                79.0  \n",
       "19                87.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create a list of float values\n",
    "float_values = np.random.uniform(low=10.5, high=99.5, size=20)\n",
    "\n",
    "# Create a DataFrame with the float values\n",
    "df_floats = pd.DataFrame(float_values, columns=['Float Values'])\n",
    "\n",
    "# Convert float values to integers directly (truncating the decimal part)\n",
    "df_floats['Integer Values'] = df_floats['Float Values'].astype(int)\n",
    "\n",
    "# Round float values before converting to integers\n",
    "df_floats['Rounded Integers'] = df_floats['Float Values'].round().astype(int)\n",
    "\n",
    "# Round float values to 4 decimal places\n",
    "df_floats['Rounded to 4 Decimals'] = df_floats['Float Values'].round(4)\n",
    "\n",
    "# Convert integer values back to floats\n",
    "df_floats['Reconverted Floats'] = df_floats['Integer Values'].astype(float)\n",
    "\n",
    "# Display the DataFrame with original float values, integer values, rounded integers, rounded to 4 decimals, and reconverted float values\n",
    "df_floats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcd2e8-8763-4325-aba5-16d21c6b8980",
   "metadata": {
    "id": "f014f51d-d912-450a-867e-eda201e871dd"
   },
   "source": [
    "<h1 style=\"color:blue;\">Numerical Precision with Point Data</h1>\n",
    "\n",
    "## Purpose\n",
    "Precision is crucial in 2D modeling and large data operations because it directly influences the accuracy of spatial calculations and the reliability of results. For instance, calculating areas for grid elements in a mesh requires high precision to avoid small errors that can propagate through an analysis. This example demonstrates how numerical precision is handled when reading mesh data and calculating grid element areas.\n",
    "\n",
    "## Examples\n",
    "Here are some common operations involving float variables that you will explore in this notebook:\n",
    "\n",
    "- **Calculate the area of each grid element in a mesh**: This operation demonstrates how spatial data (x, y coordinates) can be used to compute areas with precision.\n",
    "  \n",
    "## Instructions\n",
    "1. **Ask ChatGPT to explain float precision.** Understand how float representation can influence the accuracy of spatial calculations.\n",
    "2. **Ask ChatGPT to calculate cell size of topo.dat.** This will help you automate data reading and area calculation for meshes.\n",
    "\n",
    "By mastering precision in numerical data handling, you can enhance the accuracy of your floodplain modeling and grid analysis!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb97ddc-171a-4fe9-8bcb-6f22567fca29",
   "metadata": {},
   "source": [
    "## Example ChatGPT Query\n",
    "\n",
    "- **Objective**: Calculate the grid cell size and area for a centroid point file with space-delimited x, y, z data.\n",
    "- **Data**: Each row in the file represents a centroid with x, y, and z coordinates. No headers are present.\n",
    "- **Skip Lines**: Not applicable as there are no headers or initial lines to skip.\n",
    "- **Output Format**: Save the output in a CSV file named `topoarea.csv` with columns for x, y, z, grid size, and area.\n",
    "- **Dependencies**: Use Pandas to handle data reading, calculations, and writing to CSV.\n",
    "- **File Paths**: Include variables to set file paths for reading the input (`topo.dat`) and writing the output (`topoarea.csv`).\n",
    "- **Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids`\n",
    "- **Request**: Can you create a Python script to calculate grid sizes based on consecutive y-values and compute areas assuming square cells, then write this data to a CSV file?\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "\n",
    "The following code block is the result of this query. (Insert your Python code here if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cad01830-aa04-4314-8550-38498b403e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\topoarea.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\topo.dat'\n",
    "output_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\topoarea.csv'\n",
    "\n",
    "# Load data from space-delimited file without headers\n",
    "data = pd.read_csv(input_file_path, header=None, sep=r'\\s+', names=['x', 'y', 'z'])\n",
    "\n",
    "# Calculate grid size assuming it's determined by the difference in consecutive y-values\n",
    "data['grid_size'] = data['y'].diff().abs()\n",
    "\n",
    "# Calculate the area of the square cell (grid size squared)\n",
    "data['area'] = data['grid_size'] ** 2\n",
    "\n",
    "# Handle the first row where the grid size calculation might result in a NaN\n",
    "#data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Data saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e8a28-a424-439d-93b7-4e0a109a36f3",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Numerical Precision with Polygon Grid Data</h1>\n",
    "\n",
    "## Purpose\n",
    "Precision plays a key role in geoprocessing tasks, particularly when calculating areas from polygon grids in GIS. In this example, we calculate the area of each cell in a polygon grid system. While this method is often used in geospatial analyses, it may not be as precise as methods based on structured grid systems. Understanding the limitations of precision in such operations is crucial for accurate modeling and analysis.\n",
    "\n",
    "## Examples\n",
    "Here are some common operations involving float variables and geospatial data:\n",
    "\n",
    "- **Calculate the area of each polygon in a shapefile**: This shows how spatial polygons from a grid system can be used to compute areas.\n",
    "- **Ensure valid geometries and correct CRS**: Ensuring that the geometries are valid and in the correct coordinate system is crucial for accuracy.\n",
    "- **Convert areas to specific units**: The area can be converted to other units (e.g., hectares) as needed.\n",
    "\n",
    "## Instructions\n",
    "1. **Ask ChatGPT to define the role of CRS (Coordinate Reference System).** Understanding how CRS affects spatial calculations is essential for precision.\n",
    "2. **Request ChatGPT to create a script calculate the area of a grid shapefile.** This will help you understand how to automate geospatial data handling.\n",
    "3. **Load Shapefile in QGIS** Load the file and open the attribute table so you can use some more data editors.\n",
    "4. **Practice calculating polygon areas**: Try converting areas from square meters to other units to gain insight into precision control in geoprocessing.  This can be completed using the field calculator in QGIS. Ask ChatGPT for instructions.\n",
    "5. **Explore further operations, such as filtering or sorting the polygon data**: See how you can manage and analyze geospatial data more effectively by sorting an attribute table or filtering values within or outside of a specific range.  Ask ChatGPT how to perform this task using the Grid shapefile and the attribute table editor.\n",
    "\n",
    "By mastering these geoprocessing techniques and understanding how precision influences polygon-based grid systems, you can improve the accuracy and reliability of spatial analyses in GIS workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923fe0a-cc95-435a-ae3e-a3fa0285eb03",
   "metadata": {},
   "source": [
    "## Example Query\n",
    "- **Objective**: Calculate the grid cell size and area grid shapefile that has a single polygon for each grid element.\n",
    "- **Data**: grid.shp polygon grid element\n",
    "- **Output Format**: Save the output in a CSV file named `gridarea.csv` grid size and area.\n",
    "- **Dependencies**: Use GeoPandas to handle data reading, calculations, and writing to CSV.\n",
    "- **Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids`\n",
    "- **Request**: Can you create a Python script to calculate grid size and area based polygons in the shapefile then write this data to a CSV file?\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "\n",
    "The following code block is the result of this query. (Insert your Python code here if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fde719b-bba6-4af3-a715-4d914882d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\gridarea.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\grid.shp'\n",
    "output_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\gridarea.csv'\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file(input_file_path)\n",
    "\n",
    "# Calculate the area of each polygon (assumed to be in CRS units that represent meters or feet)\n",
    "gdf['area'] = gdf['geometry'].area\n",
    "\n",
    "# Assuming a square grid, calculate the grid size as the square root of the area\n",
    "gdf['grid_size'] = gdf['area'] ** 0.5\n",
    "\n",
    "# Save to CSV\n",
    "gdf[['grid_size', 'area']].to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Data saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d271b11e-a697-4357-a5be-377c8429387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\gridarea.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\grid.shp'\n",
    "output_file_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\Grids\\gridarea.csv'\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file(input_file_path)\n",
    "\n",
    "# Calculate the area of each polygon (assumed to be in CRS units that represent meters or feet)\n",
    "gdf['area'] = gdf['geometry'].area\n",
    "\n",
    "# Assuming a square grid, calculate the grid size as the square root of the area\n",
    "gdf['grid_size'] = gdf['area'] ** 0.5\n",
    "\n",
    "# Round grid size and area to the nearest integer\n",
    "gdf['grid_size'] = gdf['grid_size'].round().astype(int)\n",
    "gdf['area'] = gdf['area'].round().astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "gdf[['grid_size', 'area']].to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Data saved to {output_file_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d037f19-61cd-4eae-8d33-d73d4c4f548a",
   "metadata": {
    "id": "9d037f19-61cd-4eae-8d33-d73d4c4f548a"
   },
   "source": [
    "<h1 style=\"color:blue;\">Comparing Files Using Python</h1>\n",
    "\n",
    "## Introduction\n",
    "Comparing data is a common requirement in many data analysis, and system administration tasks. This section will introduce you to basic techniques for comparing files using Python.\n",
    "\n",
    "## Objectives\n",
    "- Understand how to use Python for file comparison.\n",
    "- Learn to compare text files line by line.\n",
    "- Explore methods to compare binary files.\n",
    "- Implement file comparison in practical programming scenarios.\n",
    "\n",
    "## Tools and Libraries\n",
    "- **`filecmp` module**: A module that provides functions to compare files and directories in Python.\n",
    "- **`difflib` library**: Useful for identifying differences between sequences, including lines in text files.\n",
    "\n",
    "## 1. Comparing Text Files\n",
    "To compare text files, you can read the files line by line and identify differences using the `difflib` library. This allows you to see exactly what has changed between the two files.\n",
    "\n",
    "## 2. Getting a List of Files\n",
    "To build a list of files in a directory, follow these steps:\n",
    "\n",
    "1. **Navigate to the Directory**: Open File Explorer and go to the desired directory.\n",
    "2. **Select All Files**: Press `CTRL + A` to select all files in the directory.\n",
    "3. **Copy as Path**: Hold `Shift`, right-click, and select \"Copy as path.\"\n",
    "4. This will be the list that you feed to ChatGPT.\n",
    "\n",
    "If you encounter issues with this process, you can ask ChatGPT to help build a list, even if the data is not on a single line.\n",
    "\n",
    "## 3. Getting a Script from ChatGPT\n",
    "Ask ChatGPT to write a Python script that performs the file comparison for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f587ac3-d6aa-4c28-a0a8-6f244dac18a6",
   "metadata": {},
   "source": [
    "## Example Query\n",
    "- **Objective**: Compare text files across two model folders for differences, ignoring variations in whitespace.\n",
    "- **Data**: Text files named `DEPFP.OUT, FINALDEP.OUT, FPINFILTRATION.OUT`.\n",
    "- **Output Format**: Output whether there are differences directly to the console and log specific differences to a file named `diff_log.txt`.\n",
    "- **Dependencies**: Use Python standard libraries for file handling and text manipulation.\n",
    "- **Path**: `C:\\Users\\Karen\\Chat GPT Workshop\\Data\\File Diff`\n",
    "- **Request**: Create a Python script that compares text files in 'Model1' and 'Model2' folders.\n",
    "- **White Space**: Ignore whitespace differences using strip and split methods. \n",
    "- **Output**: Write results to the console and log specific differences to a file.\n",
    "\n",
    "## ðŸ”½ Code Block\n",
    "\n",
    "The following code block is the result of this query. (Insert your Python code here if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "774f62a7-eb6c-4ea8-a5ad-a2b053c90575",
   "metadata": {
    "id": "774f62a7-eb6c-4ea8-a5ad-a2b053c90575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No differences in DEPFP.OUT.\n",
      "Differences found in FINALDEP.OUT:\n",
      "No differences in FPINFILTRATION.OUT.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def compare_files(path1, path2):\n",
    "    with open(path1, 'r') as file1, open(path2, 'r') as file2:\n",
    "        lines1 = file1.readlines()\n",
    "        lines2 = file2.readlines()\n",
    "    \n",
    "    differences = []\n",
    "    for line1, line2 in zip(lines1, lines2):\n",
    "        # Strip whitespace from the ends and split by whitespace to ignore differences within lines\n",
    "        if line1.strip().split() != line2.strip().split():\n",
    "            differences.append((line1, line2))\n",
    "    return differences\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\Karen\\Chat GPT Workshop\\Data\\File Diff'\n",
    "    models = ['Model1', 'Model2']\n",
    "    files = ['DEPFP.OUT', 'FINALDEP.OUT', 'FPINFILTRATION.OUT']\n",
    "    \n",
    "    # Create or open the log file\n",
    "    with open(os.path.join(base_path, 'diff_log.txt'), 'w') as log:\n",
    "        for file in files:\n",
    "            file_path1 = os.path.join(base_path, models[0], file)\n",
    "            file_path2 = os.path.join(base_path, models[1], file)\n",
    "            \n",
    "            if os.path.exists(file_path1) and os.path.exists(file_path2):\n",
    "                differences = compare_files(file_path1, file_path2)\n",
    "                if differences:\n",
    "                    print(f\"Differences found in {file}:\")\n",
    "                    log.write(f\"Differences in {file}:\\n\")\n",
    "                    for line1, line2 in differences:\n",
    "                        log.write(f\"Model1: {line1}Model2: {line2}\\n\")\n",
    "                else:\n",
    "                    print(f\"No differences in {file}.\")\n",
    "                    log.write(f\"No differences in {file}.\\n\")\n",
    "            else:\n",
    "                print(f\"One or both files are missing for {file}.\")\n",
    "                log.write(f\"One or both files are missing for {file}.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3303112-318a-487b-b4c7-48aa8b517535",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
