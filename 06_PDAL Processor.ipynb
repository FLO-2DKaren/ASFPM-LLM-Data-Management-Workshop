{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8620a78a",
   "metadata": {},
   "source": [
    "# ðŸ”µ âšª ðŸ”µ LiDAR to Smooth Ground Surface Using PDAL\n",
    "\n",
    "## Overview\n",
    "\n",
    "This workflow efficiently converts LiDAR point cloud data (LAZ/LAS) to a smooth ground surface raster (GeoTIFF) using PDAL (Point Data Abstraction Library). The pipeline is optimized for both speed and output quality.\n",
    "\n",
    "## âš™ï¸ Key Processing Steps Explained\n",
    "\n",
    "### 1. Ground Point Extraction (`filters.range`)\n",
    "- **Function**: Isolates only ground-classified points (Class 2 in LAS/LAZ format)\n",
    "- **Importance**: Creates a clean dataset containing only terrain surface points\n",
    "- **Performance Impact**: Reduces data volume for subsequent processing steps\n",
    "\n",
    "### 2. Outlier Removal (`filters.outlier`)\n",
    "- **Function**: Identifies and removes statistical outliers\n",
    "- **Parameters**:\n",
    "  - `mean_k`: 12 - Number of nearest neighbors to analyze\n",
    "  - `multiplier`: 2.0 - Statistical threshold for outlier identification  \n",
    "- **Importance**: Eliminates noise and erroneous points that would create artifacts\n",
    "- **Output Quality**: Creates smoother surfaces by removing spikes and holes\n",
    "\n",
    "### 3. Data Thinning (`filters.decimation`)\n",
    "- **Function**: Systematically reduces point density by keeping every nth point\n",
    "- **Parameter**: `step`: 3 - Keeps every 3rd point (reduces data by ~67%)\n",
    "- **Performance Impact**: Significantly improves processing speed\n",
    "- **Trade-off**: Slight reduction in detail, but maintains overall terrain characteristics\n",
    "\n",
    "### 4. Rasterization with Smoothing (`writers.raster`)\n",
    "- **Function**: Converts point cloud to raster grid with interpolation\n",
    "- **Parameters**:\n",
    "  - `resolution`: 2.0 - Output cell size in units of the source data\n",
    "  - `output_type`: \"idw\" - Inverse Distance Weighting interpolation\n",
    "  - `radius`: 6.0 - Search radius for influencing points\n",
    "  - `power`: 2.0 - Controls how quickly influence diminishes with distance\n",
    "- **Importance**: Creates continuous surface with natural transitions between points\n",
    "- **Output Quality**: IDW produces a smooth surface while respecting the actual elevation values\n",
    "\n",
    "### 5. Multi-threading Optimization\n",
    "- **Function**: Utilizes multiple CPU cores for parallel processing\n",
    "- **Parameter**: `thread_count`: num_cores - Automatically uses all available cores\n",
    "- **Performance Impact**: Near-linear speedup with number of cores\n",
    "\n",
    "## â±ï¸ Performance Optimization Techniques\n",
    "\n",
    "1. **Strategic Filtering Order**:\n",
    "   - Extract ground first to minimize data volume for subsequent steps\n",
    "   - Apply computationally expensive operations (outlier removal) on reduced dataset\n",
    "\n",
    "2. **Data Reduction**:\n",
    "   - Point classification filtering removes non-ground data\n",
    "   - Decimation reduces overall point count by 67%\n",
    "   - Outlier removal eliminates noise that would slow triangulation\n",
    "\n",
    "3. **Efficient Interpolation Method**:\n",
    "   - IDW provides excellent speed/quality balance compared to triangulation\n",
    "   - Configurable radius and power parameters for fine-tuning\n",
    "\n",
    "4. **Parallel Processing**:\n",
    "   - Automatic detection and utilization of all available CPU cores\n",
    "   - Thread count matching to hardware capabilities\n",
    "\n",
    "## ðŸ› ï¸ Adjustable Parameters for Different Requirements\n",
    "\n",
    "### For Higher Resolution Output\n",
    "- Decrease `resolution` (e.g., 1.0)\n",
    "- Decrease `step` in decimation (e.g., 2)\n",
    "- Increase `radius` in IDW interpolation\n",
    "\n",
    "### For Faster Processing\n",
    "- Increase `resolution` (e.g., 5.0)\n",
    "- Increase `step` in decimation (e.g., 5 or 8)\n",
    "- Decrease `mean_k` in outlier filter\n",
    "\n",
    "### For Smoother Output\n",
    "- Increase `radius` in IDW\n",
    "- Increase `power` parameter (e.g., 3.0)\n",
    "- Use a larger `mean_k` value for outlier detection\n",
    "\n",
    "## Alternative Approaches\n",
    "\n",
    "For different requirements, consider these alternative filter combinations:\n",
    "\n",
    "1. **Triangle-Based Approach**:\n",
    "   - Uses `filters.delaunay` and `filters.faceraster`\n",
    "   - Creates triangulated irregular network (TIN) before rasterization\n",
    "   - Better for preserving sharp features but slower\n",
    "\n",
    "2. **Moving Least Squares Approach** (if available):\n",
    "   - Uses `filters.mls` before rasterization\n",
    "   - Creates mathematically smooth surfaces\n",
    "   - Computationally intensive but produces very smooth results\n",
    "\n",
    "3. **Grid-Based Approach**:\n",
    "   - Uses direct grid projection methods\n",
    "   - Fastest option but potentially less smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936adeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to create a ground surface raster from LiDAR data using PDAL.\n",
    "It includes steps for filtering, decimation, outlier removal, and rasterization.\n",
    "The script is designed to be run in a Python environment with PDAL installed.\n",
    "It is assumed that the PDAL library and its dependencies are properly installed and configured.\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Determine the number of cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "input_file = os.path.join(file_path, \"USGS_LPC_AZ_MaricopaPinal_2020_B20_w0401n3720.laz\")\n",
    "output_file = os.path.join(file_path, \"ground_surface_smooth.tif\")\n",
    "\n",
    "# Enhanced pipeline for a smoother surface\n",
    "pipeline_dict = {\n",
    "  \"pipeline\":[\n",
    "    input_file,\n",
    "    # Extract ground points\n",
    "    {\n",
    "        \"type\": \"filters.range\",\n",
    "        \"limits\": \"Classification[2:2]\"\n",
    "    },\n",
    "    # Moderate thinning - balance between speed and detail\n",
    "    {\n",
    "        \"type\": \"filters.decimation\",\n",
    "        \"step\": 4  # Keep every 4th point\n",
    "    },\n",
    "    # Remove outliers for a smoother surface\n",
    "    {\n",
    "        \"type\": \"filters.outlier\",\n",
    "        \"method\": \"statistical\",\n",
    "        \"mean_k\": 8,\n",
    "        \"multiplier\": 2.0\n",
    "    },\n",
    "    # Use delaunay triangulation for smoother interpolation\n",
    "    {\n",
    "        \"type\": \"filters.delaunay\"\n",
    "    },\n",
    "    # Create a smooth raster surface from the triangulation\n",
    "    {\n",
    "        \"type\": \"filters.faceraster\",\n",
    "        \"resolution\": 1.0\n",
    "    },\n",
    "    # Write the raster output\n",
    "    {\n",
    "        \"type\": \"writers.raster\",\n",
    "        \"filename\": output_file,\n",
    "        \"gdaldriver\": \"GTiff\"\n",
    "    }\n",
    "  ],\n",
    "  \"thread_count\": num_cores\n",
    "}\n",
    "\n",
    "# Create and execute the pipeline\n",
    "start_time = time.time()\n",
    "pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "count = pipeline.execute()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Processed {count} points using {num_cores} threads\")\n",
    "print(f\"Total processing time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfea6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to create a ground surface raster from multiple LiDAR files using PDAL.\n",
    "It includes steps for filtering, decimation, outlier removal, and rasterization.\n",
    "The script processes all .laz files in the specified directory.\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# Determine the number of cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Directory containing LAZ files\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "\n",
    "# Get a list of all LAZ files in the directory\n",
    "laz_files = glob.glob(os.path.join(file_path, \"*.laz\"))\n",
    "\n",
    "print(f\"Found {len(laz_files)} LAZ files to process.\")\n",
    "\n",
    "# Process each LAZ file\n",
    "for input_file in laz_files:\n",
    "    # Create output filename based on input filename\n",
    "    base_name = os.path.basename(input_file)\n",
    "    output_name = os.path.splitext(base_name)[0] + \"_ground_surface.tif\"\n",
    "    output_file = os.path.join(file_path, output_name)\n",
    "    \n",
    "    print(f\"\\nProcessing file: {base_name}\")\n",
    "    print(f\"Output will be saved as: {output_name}\")\n",
    "    \n",
    "    # Enhanced pipeline for a smoother surface\n",
    "    pipeline_dict = {\n",
    "      \"pipeline\":[\n",
    "        input_file,\n",
    "        # Extract ground points\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        },\n",
    "        # Moderate thinning - balance between speed and detail\n",
    "        {\n",
    "            \"type\": \"filters.decimation\",\n",
    "            \"step\": 4  # Keep every 4th point\n",
    "        },\n",
    "        # Remove outliers for a smoother surface\n",
    "        {\n",
    "            \"type\": \"filters.outlier\",\n",
    "            \"method\": \"statistical\",\n",
    "            \"mean_k\": 8,\n",
    "            \"multiplier\": 2.0\n",
    "        },\n",
    "        # Use delaunay triangulation for smoother interpolation\n",
    "        {\n",
    "            \"type\": \"filters.delaunay\"\n",
    "        },\n",
    "        # Create a smooth raster surface from the triangulation\n",
    "        {\n",
    "            \"type\": \"filters.faceraster\",\n",
    "            \"resolution\": 1.0\n",
    "        },\n",
    "        # Write the raster output\n",
    "        {\n",
    "            \"type\": \"writers.raster\",\n",
    "            \"filename\": output_file,\n",
    "            \"gdaldriver\": \"GTiff\"\n",
    "        }\n",
    "      ],\n",
    "      \"thread_count\": num_cores\n",
    "    }\n",
    "    \n",
    "    # Create and execute the pipeline\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "        count = pipeline.execute()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Successfully processed {count} points using {num_cores} threads\")\n",
    "        print(f\"Processing time: {elapsed_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_name}: {e}\")\n",
    "\n",
    "print(\"\\nAll files processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cae12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "\n",
    "# This is the most reliable approach - merge the point clouds BEFORE rasterization\n",
    "\n",
    "# Find all LAZ files\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "laz_files = glob.glob(os.path.join(file_path, \"*.laz\"))\n",
    "output_merged = os.path.join(file_path, \"merged_ground_surface.tif\")\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Create a PDAL pipeline that merges all point clouds first, then creates a single raster\n",
    "pipeline_dict = {\n",
    "  \"pipeline\": [\n",
    "    # Use all LAZ files as input\n",
    "    *laz_files,\n",
    "    {\n",
    "        \"type\": \"filters.merge\"  # Merge all point clouds into one\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filters.range\",\n",
    "        \"limits\": \"Classification[2:2]\"  # Extract ground points\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filters.outlier\",\n",
    "        \"method\": \"statistical\",\n",
    "        \"mean_k\": 8,\n",
    "        \"multiplier\": 2.0\n",
    "    },\n",
    "    # Create a single TIN across the entire dataset\n",
    "    {\n",
    "        \"type\": \"filters.delaunay\"\n",
    "    },\n",
    "    # Rasterize the entire TIN at once - eliminates edge effects\n",
    "    {\n",
    "        \"type\": \"filters.faceraster\",\n",
    "        \"resolution\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"writers.raster\",\n",
    "        \"filename\": output_merged,\n",
    "        \"gdaldriver\": \"GTiff\",\n",
    "        \"gdalopts\": \"COMPRESS=LZW,BIGTIFF=YES\"\n",
    "    }\n",
    "  ],\n",
    "  \"thread_count\": num_cores\n",
    "}\n",
    "\n",
    "# Execute the pipeline\n",
    "pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "count = pipeline.execute()\n",
    "print(f\"Processed {count} points into a seamless raster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed2347af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 LAZ files to process\n",
      "\n",
      "Processing file 1/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0401n3720.laz\n",
      "  Processed 1978057 points in 25.04 seconds\n",
      "\n",
      "Processing file 2/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0401n3721.laz\n",
      "  Processed 2036293 points in 30.29 seconds\n",
      "\n",
      "Processing file 3/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0402n3720.laz\n",
      "  Processed 2252174 points in 32.03 seconds\n",
      "\n",
      "Processing file 4/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0402n3721.laz\n",
      "  Processed 2492533 points in 33.84 seconds\n",
      "\n",
      "Processing file 5/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0403n3720.laz\n",
      "  Processed 2079105 points in 30.12 seconds\n",
      "\n",
      "Processing file 6/6: USGS_LPC_AZ_MaricopaPinal_2020_B20_w0403n3721.laz\n",
      "  Processed 2159343 points in 30.34 seconds\n",
      "\n",
      "Creating seamless mosaic with enhanced blending...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 182\u001b[0m\n\u001b[0;32m    179\u001b[0m resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Process the data with the modified approach\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[43mprocess_lidar_scalable_no_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlidar_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_epsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2223\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 144\u001b[0m, in \u001b[0;36mprocess_lidar_scalable_no_buffer\u001b[1;34m(lidar_dir, output_dir, target_resolution, target_epsg)\u001b[0m\n\u001b[0;32m    135\u001b[0m filled_mosaic \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilled_mosaic_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_resolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mft.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m gdal_fillnodata_cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdal_fillnodata.py\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-md\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Maximum search distance in pixels\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     filled_mosaic\n\u001b[0;32m    142\u001b[0m ]\n\u001b[1;32m--> 144\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdal_fillnodata_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Reproject to target CRS\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_epsg \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\flo2d_env\\Lib\\subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    548\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\flo2d_env\\Lib\\subprocess.py:1028\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1025\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1026\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1028\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\flo2d_env\\Lib\\subprocess.py:1540\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1540\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1556\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1557\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scalable LiDAR processing workflow for hydrologic/hydraulic modeling:\n",
    "1. Process LiDAR tiles with consistent parameters\n",
    "2. Create consistent, lower-resolution surfaces\n",
    "3. Generate a seamless mosaic suitable for visualization and modeling\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "from osgeo import gdal\n",
    "import subprocess\n",
    "\n",
    "def process_lidar_scalable_no_buffer(lidar_dir, output_dir, target_resolution=10.0, target_epsg=2223):\n",
    "    \"\"\"\n",
    "    Process multiple LiDAR files for hydraulic modeling with a focus on scalability\n",
    "    Uses only standard PDAL filters that are widely available\n",
    "    \n",
    "    Parameters:\n",
    "    - lidar_dir: Directory containing LAZ files\n",
    "    - output_dir: Directory for output files\n",
    "    - target_resolution: Resolution in feet (default 10ft for hydraulic modeling)\n",
    "    - target_epsg: Target coordinate system (default EPSG:2223)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Find all LAZ files\n",
    "    laz_files = glob.glob(os.path.join(lidar_dir, \"*.laz\"))\n",
    "    print(f\"Found {len(laz_files)} LAZ files to process\")\n",
    "    \n",
    "    # Number of cores to use\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    \n",
    "    # Step 2: Process each LAZ file with extended boundaries\n",
    "    processed_tiles = []\n",
    "    \n",
    "    for i, laz_file in enumerate(laz_files):\n",
    "        print(f\"\\nProcessing file {i+1}/{len(laz_files)}: {os.path.basename(laz_file)}\")\n",
    "        \n",
    "        # Create output filename\n",
    "        base_name = os.path.splitext(os.path.basename(laz_file))[0]\n",
    "        output_raster = os.path.join(output_dir, f\"{base_name}_ground_{target_resolution}ft.tif\")\n",
    "        processed_tiles.append(output_raster)\n",
    "        \n",
    "        # Create PDAL pipeline without buffer (not available in your installation)\n",
    "        pipeline_dict = {\n",
    "          \"pipeline\": [\n",
    "            laz_file,\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"Classification[2:2]\"  # Extract ground points\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.decimation\",\n",
    "                \"step\": 4  # Reduce point count for large datasets\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"statistical\",\n",
    "                \"mean_k\": 8,\n",
    "                \"multiplier\": 2.0\n",
    "            },\n",
    "            # Use delaunay triangulation for a smooth surface\n",
    "            {\n",
    "                \"type\": \"filters.delaunay\"\n",
    "            },\n",
    "            # Create raster at the target resolution (e.g., 10ft)\n",
    "            {\n",
    "                \"type\": \"filters.faceraster\",\n",
    "                \"resolution\": target_resolution\n",
    "            },\n",
    "            # Write the raster output\n",
    "            {\n",
    "                \"type\": \"writers.raster\",\n",
    "                \"filename\": output_raster,\n",
    "                \"gdaldriver\": \"GTiff\",\n",
    "                \"gdalopts\": \"COMPRESS=LZW,BIGTIFF=YES\"\n",
    "            }\n",
    "          ],\n",
    "          \"thread_count\": num_cores\n",
    "        }\n",
    "        \n",
    "        # Execute the pipeline\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "            count = pipeline.execute()\n",
    "            end_time = time.time()\n",
    "            print(f\"  Processed {count} points in {end_time - start_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {base_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Step 3: Create a seamless mosaic with enhanced blending\n",
    "    print(\"\\nCreating seamless mosaic with enhanced blending...\")\n",
    "    \n",
    "    # Output for the merged result\n",
    "    mosaic_output = os.path.join(output_dir, f\"seamless_mosaic_{target_resolution}ft.tif\")\n",
    "    reprojected_output = os.path.join(output_dir, f\"seamless_mosaic_{target_resolution}ft_epsg{target_epsg}.tif\")\n",
    "    \n",
    "    # Create a VRT to merge the tiles\n",
    "    vrt_path = os.path.join(output_dir, \"temp_mosaic.vrt\")\n",
    "    \n",
    "    # Use gdalbuildvrt command line with additional options\n",
    "    gdalbuildvrt_cmd = [\n",
    "        'gdalbuildvrt',\n",
    "        '-resolution', 'highest',\n",
    "        '-a_srs', 'EPSG:4326',  # Ensure correct source SRS\n",
    "        '-r', 'average',\n",
    "        vrt_path\n",
    "    ] + processed_tiles\n",
    "    \n",
    "    subprocess.run(gdalbuildvrt_cmd)\n",
    "    \n",
    "    # Create mosaic with a very large blending distance to compensate for lack of buffering\n",
    "    gdalwarp_cmd = [\n",
    "        'gdalwarp',\n",
    "        '-co', 'COMPRESS=LZW',\n",
    "        '-co', 'BIGTIFF=YES',\n",
    "        '-r', 'cubic',  # Cubic interpolation for smoother results\n",
    "        '-wo', 'CUTLINE_BLEND_DIST=100',  # Very large blend distance (10x the resolution)\n",
    "        '-wo', 'UNIFIED_SRC_NODATA=YES',\n",
    "        '-dstnodata', '-9999',  # Explicit NoData value\n",
    "        '-multi',  # Use multithreading\n",
    "        vrt_path,\n",
    "        mosaic_output\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(gdalwarp_cmd)\n",
    "    \n",
    "    # Additional step: Fill any remaining NoData gaps\n",
    "    filled_mosaic = os.path.join(output_dir, f\"filled_mosaic_{target_resolution}ft.tif\")\n",
    "    gdal_fillnodata_cmd = [\n",
    "        'gdal_fillnodata.py',\n",
    "        '-md', '10',  # Maximum search distance in pixels\n",
    "        '-si', '0',   # No smoothing iterations\n",
    "        mosaic_output,\n",
    "        filled_mosaic\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(gdal_fillnodata_cmd)\n",
    "    \n",
    "    # Reproject to target CRS\n",
    "    if target_epsg != 0:\n",
    "        print(f\"Reprojecting to EPSG:{target_epsg}...\")\n",
    "        gdalwarp_reproj_cmd = [\n",
    "            'gdalwarp',\n",
    "            '-co', 'COMPRESS=LZW',\n",
    "            '-co', 'BIGTIFF=YES',\n",
    "            '-r', 'cubic',\n",
    "            '-t_srs', f'EPSG:{target_epsg}',\n",
    "            '-multi',\n",
    "            filled_mosaic,\n",
    "            reprojected_output\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(gdalwarp_reproj_cmd)\n",
    "    \n",
    "    # Clean up\n",
    "    if os.path.exists(vrt_path):\n",
    "        os.remove(vrt_path)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Seamless mosaic: {filled_mosaic}\")\n",
    "    if target_epsg != 0:\n",
    "        print(f\"Reprojected mosaic: {reprojected_output}\")\n",
    "    \n",
    "    return filled_mosaic, reprojected_output if target_epsg != 0 else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your directories and parameters\n",
    "    lidar_directory = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "    output_directory = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\\Processed\"\n",
    "    \n",
    "    # Set resolution to 10 feet (common for hydraulic modeling)\n",
    "    resolution = 10.0\n",
    "    \n",
    "    # Process the data with the modified approach\n",
    "    process_lidar_scalable_no_buffer(lidar_directory, output_directory, resolution, target_epsg=2223)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flo2d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
