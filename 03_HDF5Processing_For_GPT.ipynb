{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pzQ2WIjuqtq6",
   "metadata": {
    "id": "pzQ2WIjuqtq6"
   },
   "source": [
    "# üìä HDF5 Data Processing with Python and ChatGPT\n",
    "\n",
    "Welcome to **HDF5 Data Processing**! In this session, we will use **ChatGPT**, **HDF5**, and **Python** to efficiently store, manipulate, and analyze large datasets.\n",
    "\n",
    "## üìå What You Will Learn\n",
    "1. Set up your computer for **Python scripting** and **HDF5 file processing**.\n",
    "2. Use **ChatGPT** to generate and debug **HDF5 queries**.\n",
    "3. Learn best practices for **efficient data management** with HDF5.\n",
    "4. Process and analyze **HDF5 datasets** using **Python and Numpy**.\n",
    "\n",
    "## üõ†Ô∏è Required Programs\n",
    "- **Python** (Version 3.12 or later)\n",
    "- **HDF5 View** (Library for hierarchical data storage)\n",
    "- **h5py** (Python library for working with HDF5 files)\n",
    "- **Numpy** (For reading and analyzing HDF5 data)\n",
    "\n",
    "## Optionl Sections\n",
    "- **imageio**\n",
    "- **FFPMEG**\n",
    "- **MatPlotLib**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è Run the Test Cell  \n",
    "Before we begin, run the test cell below to check your setup.\n",
    "\n",
    "This test will:\n",
    "- ‚úÖ Verify that **HDF5 (h5py)** is available.\n",
    "- ‚úÖ Check if **Pandas** is installed.\n",
    "- ‚úÖ Confirm that an **HDF5 file can be created and accessed**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd8d6c-3376-4145-a74f-2a5868b5b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# Checking HDF5 and Pandas Setup\n",
    "\n",
    "# Automatically set base path to the project directory where the notebook is running\n",
    "from pathlib import Path\n",
    "\n",
    "# This gets the directory where the current notebook is located\n",
    "base_path = Path.cwd()\n",
    "\n",
    "print(f\"üìÇ Base path automatically set to: {base_path}\")\n",
    "\n",
    "print(\"üîç Checking system setup...\\n\")\n",
    "\n",
    "# Test h5py (HDF5 support)\n",
    "try:\n",
    "    import h5py\n",
    "    with h5py.File(\"test.hdf5\", \"w\") as f:\n",
    "        f.create_dataset(\"test_data\", data=[1, 2, 3, 4, 5])\n",
    "    print(\"‚úÖ HDF5 (h5py) is available and working!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå HDF5 test failed: {e}\")\n",
    "\n",
    "# Test Pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"‚úÖ Pandas imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Pandas is not installed. Run `pip install pandas`.\")\n",
    "\n",
    "# Confirm Python version\n",
    "import sys\n",
    "print(f\"üêç Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Test complete! If you see any ‚ùå marks, install missing dependencies before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259d58d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> \n",
    "\n",
    "Copy the Basepath to ChatGPT memory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d13ee",
   "metadata": {},
   "source": [
    "# üìä Explore HDF5 Data Structure with Python\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Understand the internal structure of HDF5 files before analysis. Use ChatGPT to help **generate a Python function** that explores the structure of your local file. This function will help list attributes, groups, datasets, and their properties, which is critical for knowing what and how to extract data.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1 - ü§ñ Ask ChatGPT for a File Explorer Function\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b> \n",
    "\n",
    "Write a Python function to explore an HDF5 file structure.  \n",
    "The function should:\n",
    "- List all groups and datasets with their full path\n",
    "- Display each object's type, shape, and data type\n",
    "- Include attributes at each level\n",
    "- Work robustly on any HDF5 file\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 ‚Äì Run the Function on Your Local Files\n",
    "\n",
    "Once you have the function:\n",
    "\n",
    "- Save it into a new cell in your notebook.\n",
    "- Set your file path to one of the following test files from the workshop:\n",
    "\n",
    "\n",
    "file_path = r'C:\\your_project_path\\Data\\HDF5\\TIMDEPNC.HDF5'\n",
    "## or\n",
    "file_path = r'C:\\your_project_path\\Data\\HDF5\\RAS_Muncie.p04.hdf'\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>Important:</b> Uploading large files to ChatGPT is not efficient.  While is it possible to upload *.hdf5 files to a GPT, it is usually faster to process the files on your own computer. </div>\n",
    "\n",
    "##  Bonus Prompt\n",
    "Once the structure looks good, ask ChatGPT:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Prompt:</b> Now write a Jupyter Notebook cell to extract data from a specific dataset in my local HDF5 file. The file is located in \"Data\\HDF5\\\" relative to the notebook. </div> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# HDF5 Exploration Function\n",
    "# This function explores an HDF5 file and prints information about its contents.\n",
    "  \n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def explore_hdf5(filepath, target_path=\"/\", indent=0):\n",
    "    \"\"\"\n",
    "    Recursively explores an HDF5 file and prints information about each group, dataset, and attribute.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath: str, path to the HDF5 file\n",
    "    - target_path: str, internal path in the HDF5 file to start exploration\n",
    "    - indent: int, current indentation level for pretty printing\n",
    "    \"\"\"\n",
    "    def print_info(name, obj, level):\n",
    "        spacing = ' ' * level\n",
    "        full_path = obj.name\n",
    "        obj_type = type(obj).__name__\n",
    "        print(f\"{spacing}Path: {full_path}\")\n",
    "        print(f\"{spacing}Type: {obj_type}\")\n",
    "\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"{spacing} - Shape: {obj.shape}\")\n",
    "            print(f\"{spacing} - Data type: {obj.dtype}\")\n",
    "            try:\n",
    "                print(f\"{spacing} - Dataspace (dims): {obj.shape}\")\n",
    "                print(f\"{spacing} - Datatype (HDF5 native): {obj.id.get_type().get_class()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{spacing} - Error reading dataspace/datatype: {e}\")\n",
    "        elif isinstance(obj, h5py.Group):\n",
    "            print(f\"{spacing} - Contains: {len(obj)} items\")\n",
    "\n",
    "        # Print attributes\n",
    "        if obj.attrs:\n",
    "            print(f\"{spacing} - Attributes:\")\n",
    "            for key, val in obj.attrs.items():\n",
    "                print(f\"{spacing}   * {key}: {val}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        def recursive_visit(group, level=0):\n",
    "            for key in group:\n",
    "                item = group[key]\n",
    "                print_info(key, item, level)\n",
    "                if isinstance(item, h5py.Group):\n",
    "                    recursive_visit(item, level + 2)\n",
    "\n",
    "        root = file[target_path]\n",
    "        print_info(target_path, root, indent)\n",
    "        if isinstance(root, h5py.Group):\n",
    "            recursive_visit(root, indent + 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26323b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# Explore the specified paths (FLO-2D)\n",
    "\n",
    "import os  # Import the os module\n",
    "\n",
    "FLO_2D_timdepnc_file = os.path.join(\"Data\", \"Hdf5\", \"TIMDEPNC.HDF5\")\n",
    "print(\"Exploring TIMDEPNC.HDF5:\\n\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"TIMDEP OUTPUT RESULTS/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0eb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Cell\n",
    "# Explore the specified paths (HEC-RAS 2D)\n",
    "\n",
    "ras_file = os.path.join(\"Data\", \"Hdf5\", \"RAS_Muncie.p04.hdf\")\n",
    "print(\"\\nExploring RAS_Muncie.p04.hdf:\\n\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a233c6a",
   "metadata": {},
   "source": [
    "# üìä User-Guided Data Exploration of HDF5 Files \n",
    "\n",
    "Now that we have a detailed description of the HDF's data contents, let's build functions to extract the data.  While this detailed information is not required, it is very helpful to reduce up-front errors and iterations.  \n",
    "\n",
    "To include this information in ChatGPT, copy the cell output and paste into ChatGPT:   \n",
    "\n",
    "\n",
    "Go to the previous output cell:  Copy the Cell Output and paste into ChatGPT\n",
    "\n",
    "![VS Code - Copy Cell Output](images/vscode-copycelloutput.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3c4c2",
   "metadata": {},
   "source": [
    "# ü§ñ Prompt: Extracting FLO-2D Water Surface Elevation Results\n",
    "\n",
    "Follow along by opening the file `Data/hdf5/TIMDEPNC.HDF5` in HDFView.  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b> \n",
    "\n",
    "- **Water Surface Elevation Data**: Stored in TIMDEPNC.HDF5 at path `/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/`, containing water surface values for each grid element over time.  \n",
    "- **Depth Data**: Stored at `/TIMDEP OUTPUT RESULTS/FLOW DEPTH/`, containing depth values over time.  \n",
    "- **Time Intervals**: Found in `/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times`.  \n",
    "- **X and Y Coordinates**: Stored at `/TIMDEP OUTPUT RESULTS/X-Coordinate/Values` and `/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values`.\n",
    "\n",
    "Ask ChatGPT to write a function that extracts WSE as an `xarray`, then plots the WSE for the time step with the maximum depth.\n",
    "\n",
    "üìå Follow-up Prompt:  \n",
    "Provide a code cell for my local notebook. The file is at `Data/Hdf5/TIMDEPNC.HDF5`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# RUN THIS CELL AND INCLUDE THE OUTPUT WITH YOUR REQUEST TO IMPROVE CONTEXT\n",
    "\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"TIMDEP OUTPUT RESULTS/FLOW DEPTH/\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# Read and Plot HDF5 Data\n",
    "# This code reads the HDF5 file and plots the water surface elevation (WSE) \n",
    "# at the time of maximum depth.\n",
    "\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local HDF5 file path\n",
    "file_path = os.path.join(base_path, 'Data', 'Hdf5', 'TIMDEPNC.HDF5')\n",
    "\n",
    "\n",
    "# Read data from file\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    wse = f['/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values'][:]  # (200, 8588)\n",
    "    depth = f['/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values'][:]             # (200, 8588)\n",
    "    times = f['/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times'][:]              # (200,)\n",
    "    x_coords = f['/TIMDEP OUTPUT RESULTS/X-Coordinate/Values'][:].flatten()  # (8588,)\n",
    "    y_coords = f['/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values'][:].flatten()  # (8588,)\n",
    "\n",
    "# Confirm shape assumptions\n",
    "assert wse.shape[1] == len(x_coords) == len(y_coords), \"Mismatch in grid size.\"\n",
    "\n",
    "# Find the time index with the maximum overall depth\n",
    "max_depth_idx = np.nanargmax(depth.max(axis=1))\n",
    "max_time = times[max_depth_idx]\n",
    "\n",
    "# Build an xarray dataset\n",
    "ds = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        wse=([\"time\", \"grid\"], wse),\n",
    "        depth=([\"time\", \"grid\"], depth)\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=times,\n",
    "        grid=np.arange(wse.shape[1]),\n",
    "        x=(\"grid\", x_coords),\n",
    "        y=(\"grid\", y_coords),\n",
    "    ),\n",
    "    attrs=dict(description=\"FLO-2D TIMDEP output\")\n",
    ")\n",
    "\n",
    "# Plot WSE at the time of max depth\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sc = ax.scatter(ds.x, ds.y, c=ds.wse.sel(time=max_time), cmap='viridis')\n",
    "plt.colorbar(sc, ax=ax, label=\"Water Surface Elevation (ft)\")\n",
    "ax.set_title(f\"WSE at Time = {max_time:.2f} hrs\")\n",
    "ax.set_xlabel(\"X Coordinate (ft)\")\n",
    "ax.set_ylabel(\"Y Coordinate (ft)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e8631",
   "metadata": {},
   "source": [
    "If you don't see something similar to this output, adjust the prompt, provide corrections or try again!\n",
    "\n",
    "![HDF-FLO-2D WSE Map in ChatGPT](images/hdf-flo2d_wse_map.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4503c",
   "metadata": {},
   "source": [
    "Try these follow-up prompts to explore the information available in the HDF: \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b> \n",
    "\n",
    "- Now map the Flow Depth at the same time step\n",
    "- I want to create an animation of maximum water surface showing the full simulation.  Export as gif, and include instructions for inline jupyter installation of any required packages.\n",
    "\n",
    "(Note, this will require installing ffmpeg or additional packages)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65006401",
   "metadata": {},
   "source": [
    "[ChatGPT Conversation - FLO-2D HDF Data Extraction](https://chatgpt.com/share/67f29600-f218-8010-8a3e-42ea9300c60d)\n",
    "\n",
    "Code Cells from these follow-up requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# Plotting Flow Depth at Maximum Depth Time Step\n",
    "# This code reads the HDF5 file and plots the flow depth at the time of maximum depth.\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define path to HDF5 file\n",
    "hdf5_path = os.path.join(base_path, 'Data', 'Hdf5', 'TIMDEPNC.HDF5')\n",
    "\n",
    "# Open the HDF5 file and extract required datasets\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    depth_values = f[\"/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values\"][:]          # (time, grid)\n",
    "    depth_times = f[\"/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times\"][:]            # (time,)\n",
    "    x_coords = f[\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\"][:].flatten()  # (8588,)\n",
    "    y_coords = f[\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\"][:].flatten()  # (8588,)\n",
    "\n",
    "# Extract depth at the timestep with max depth\n",
    "depth_at_max_time = depth_values[max_depth_idx, :]\n",
    "\n",
    "# Plot the Flow Depth\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_coords,\n",
    "    y_coords,\n",
    "    c=depth_at_max_time,\n",
    "    s=10,\n",
    "    cmap='Blues'\n",
    ")\n",
    "plt.colorbar(label='Flow Depth (ft or m)')\n",
    "plt.title(f\"Flow Depth at Time = {depth_times[max_depth_idx]:.2f} hours (Max Depth)\")\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a133d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "# Install required packages if not already installed\n",
    "# This is a quick way to install python packages in a Jupyter notebook environment.\n",
    "!pip install imageio tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ca3e1",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201e12c",
   "metadata": {},
   "source": [
    "# ü§ñ Prompt for Extracting **HEC-RAS 2D Water Surface Elevation Results**\n",
    "\n",
    "Follow along by opening the file `Data/hdf5/RAS_Muncie.p04.hdf` in HDFView.  Feed this information to ChatGPT for some help with extracting HEC-RAS results.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b>\n",
    "\n",
    "- **Mesh Name Lookup**: 2D area names can be found in /Results/Unsteady/Geometry Info/2D Area(s).  Results are available for each 2D flow area, and the 2D area name is part of the path so it must be retrieved first (as a list).  In the example HDF file provided, flow_area_name is \"2D Interior Area\" (only one 2D area)\n",
    "\n",
    "- **Mesh Cell Centers** can be found here: `/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate`\n",
    "    \n",
    "- **Time Date Stamp**: Time stamps are available at this path: `/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp` Time Date Stamp is in this format: 02JAN1900 00:00:00\n",
    "\n",
    "- **Water Surface Elevation Time Series Results**  Water Surface Elevations for each Mesh Cell are located at `/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface`\n",
    "\n",
    "- **Instructions**: \n",
    "Provide functions to extract Water Surface Elevation spatial time series to an Xarray and plot the xarray for the time step.  Use your code interpreter to test the functions and map the results to review.  Use the time step with the maximum depth to map results for review.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Instructions: \n",
    "1. Upload RAS_Muncie.p04.hdf and ask ChatGPT to write a script that can print the structure of an hdf5 file, using it's Code Interpreter.\n",
    "3. Review outputs and provide any follow-up instructions needed. \n",
    "2. Ask for a code cell for your local jupyter notebook, providing your local data file paths to ChatGPT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL AND INCLUDE THE OUTPUT WITH YOUR REQUEST TO IMPROVE CONTEXT\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Geometry Info/2D Area(s)\")\n",
    "explore_hdf5(ras_file, target_path=\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e2f1e",
   "metadata": {},
   "source": [
    "Example Output from ChatGPT's Code Interpreter\n",
    "\n",
    "![ChatGPT - HEC-RAS 2D WSE Map](images/hdf-hecras_wse_map.png)\n",
    "\n",
    "[ChatGPT Conversation for Following Code Cells](https://chatgpt.com/share/67f2a034-5874-8010-9472-bb32f2f38252)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b85b16",
   "metadata": {},
   "source": [
    "Try these follow-up prompts to explore the information available in the HDF: \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b>\n",
    "\n",
    "- Now map the Flow Depth at the same time step.  Use '/Geometry/2D Flow Areas/2D Interior Area/Cells Minimum Elevation' to calculate depth for each cell.\n",
    "\n",
    "- Provide a code cell for my local jupyter notebook for both WSE and Depth. The local path is Data/Hdf5/RAS_Muncie.p04.hdf\n",
    "\n",
    "- I want to create an animation of maximum water surface showing the full simulation.  Export as gif, and include instructions for inline jupyter installation of any required packages\n",
    "\n",
    "(Note, this will require installing ffmpeg or additional packages)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f96903-0e16-4d6b-a8a0-cc3bfe729004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Load the HDF5 file ===\n",
    "file_path = \"Data/Hdf5/RAS_Muncie.p04.hdf\"\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "\n",
    "    # === Load datasets ===\n",
    "    wse = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\"][()]\n",
    "    coords = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\"][()]\n",
    "    min_elev = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Minimum Elevation\"][()]\n",
    "    time_stamps = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\"][()].astype(str)\n",
    "\n",
    "# === Parse time and coordinates ===\n",
    "x_coords, y_coords = coords[:, 0], coords[:, 1]\n",
    "time_index = pd.to_datetime(time_stamps, format=\"%d%b%Y %H:%M:%S\")\n",
    "\n",
    "# === Create xarray for WSE ===\n",
    "wse_xr_ras = xr.DataArray(\n",
    "    wse,\n",
    "    dims=[\"time\", \"cell\"],\n",
    "    coords={\"time\": time_index, \"x\": (\"cell\", x_coords), \"y\": (\"cell\", y_coords)},\n",
    "    name=\"water_surface_elevation\",\n",
    "    attrs={\"units\": \"ft\"}\n",
    ")\n",
    "\n",
    "# === Identify timestep with maximum average WSE ===\n",
    "max_time_idx = wse_xr_ras.mean(dim=\"cell\").argmax().item()\n",
    "max_time = time_index[max_time_idx]\n",
    "wse_at_max = wse_xr_ras.sel(time=max_time)\n",
    "\n",
    "# === Calculate Flow Depth ===\n",
    "flow_depth = wse_at_max - min_elev\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    wse_xr_ras[\"x\"].values,\n",
    "    wse_xr_ras[\"y\"].values,\n",
    "    c=flow_depth.values,\n",
    "    cmap=\"Blues\",\n",
    "    s=8,\n",
    "    edgecolor=\"none\"\n",
    ")\n",
    "plt.colorbar(scatter, label=\"Flow Depth (ft)\")\n",
    "plt.title(f\"Flow Depth at Max WSE Time Step\\nTime: {max_time}\")\n",
    "plt.xlabel(\"X Coordinate (ft)\")\n",
    "plt.ylabel(\"Y Coordinate (ft)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf7e6f",
   "metadata": {},
   "source": [
    "# üåä OPTIONAL: SAVE FLO-2D ANIMATION AS GIF\n",
    "\n",
    "Chat GPT can help if you provide these instructions for making the animation. Copy these instructions and short code blocks right into the GPT so it can build the code for your notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b> \n",
    "\n",
    "\n",
    "use these additional modules:\n",
    "h5py, numpy, matplotlib.pyplot, imageio, \n",
    "tqdm # Optional: for progress bar\n",
    "\n",
    "\n",
    "### Load the HDF5 file\n",
    "hdf5_path = \"Data/Hdf5/TIMDEPNC.HDF5\"\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    wse_values = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values\"][:]\n",
    "    wse_times = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\"][:]\n",
    "    x_coords = f[\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\"][:].flatten()\n",
    "    y_coords = f[\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\"][:].flatten()\n",
    "\n",
    "### Create a folder to store frames\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "### Generate and save each frame\n",
    "filenames = []\n",
    "for i in tqdm(range(len(wse_times))):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(x_coords, y_coords, c=wse_values[i], s=10, cmap='viridis')\n",
    "    plt.colorbar(label=\"Water Surface Elevation (ft or m)\")\n",
    "    plt.title(f\"WSE at Time = {wse_times[i]:.2f} hrs\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = f\"frames/frame_{i:03d}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "    filenames.append(fname)\n",
    "\n",
    "### Create GIF\n",
    "gif_path = \"wse_animation_FLO-2D.gif\"\n",
    "with imageio.get_writer(gif_path, mode='I', duration=0.2) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "### Clean up frames (optional)\n",
    "for filename in filenames:\n",
    "    os.remove(filename)\n",
    "\n",
    "print(f\"Animation saved as {gif_path}\")\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dcda8-0717-4302-a1f5-6141aa5f62e9",
   "metadata": {},
   "source": [
    "### OPTIONAL: SAVE HEC-RAS AS GIF (TAKES 2-3 MINUTES TO PROCESS)\n",
    "\n",
    "Feed this mix of code and instructions right into the GPT.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b>\n",
    "\n",
    "### Install required packages (run this in a Jupyter notebook cell)\n",
    "!pip install xarray matplotlib imageio --quiet\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "### --- Load Data ---\n",
    "file_path = \"Data/Hdf5/RAS_Muncie.p04.hdf\"\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    wse_data = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\"][()]\n",
    "    coords = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\"][()]\n",
    "    time_stamps = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\"][()].astype(str)\n",
    "\n",
    "### --- Set Up xarray ---\n",
    "x_coords, y_coords = coords[:, 0], coords[:, 1]\n",
    "time_index = pd.to_datetime(time_stamps, format=\"%d%b%Y %H:%M:%S\")\n",
    "\n",
    "wse_xr_ras = xr.DataArray(\n",
    "    wse_data,\n",
    "    dims=[\"time\", \"cell\"],\n",
    "    coords={\n",
    "        \"time\": time_index,\n",
    "        \"x\": (\"cell\", x_coords),\n",
    "        \"y\": (\"cell\", y_coords)\n",
    "    },\n",
    "    name=\"water_surface_elevation\"\n",
    ")\n",
    "\n",
    "### --- Prepare Animation ---\n",
    "filenames = []\n",
    "vmin, vmax = np.nanmin(wse_data), np.nanmax(wse_data)  # consistent color scale\n",
    "\n",
    "for i, t in tqdm(enumerate(wse_xr_ras.time.values), total=wse_xr_ras.sizes['time']):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sc = ax.scatter(wse_xr_ras.x, wse_xr_ras.y, c=wse_xr_ras.sel(time=t), cmap=\"viridis\", s=8, vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(sc, ax=ax, label=\"Water Surface Elevation (ft)\")\n",
    "    ax.set_title(f\"WSE Time: {pd.to_datetime(t).strftime('%Y-%m-%d %H:%M')}\")\n",
    "    ax.set_xlabel(\"X Coordinate (ft)\")\n",
    "    ax.set_ylabel(\"Y Coordinate (ft)\")\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"_frame_{i:04d}.png\"\n",
    "    plt.savefig(filename)\n",
    "    filenames.append(filename)\n",
    "    plt.close()\n",
    "\n",
    "### --- Create GIF ---\n",
    "with imageio.get_writer(\"wse_animation_RAS.gif\", mode=\"I\", duration=0.2) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "### --- Cleanup PNGs ---\n",
    "import os\n",
    "for filename in filenames:\n",
    "    os.remove(filename)\n",
    "\n",
    "print(\"‚úÖ Animation saved as wse_animation.gif\")\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679aca8",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c46293",
   "metadata": {},
   "source": [
    "# üìä Using your Jupyter Notebook as Context to Add Functionality\n",
    "\n",
    "For the rest of the exercise, we will use the new line of reasoning models (o1), using this notebook as context.  \n",
    "\n",
    "Provide this notebook to any of the following models:\n",
    "\n",
    "- ChatGPT\n",
    "    - [o1](https://chatgpt.com/?model=o1)\n",
    "    - [o3-mini high](https://chatgpt.com/?model=o3-mini-high)  \n",
    "    \n",
    "    NOTE: For ChatGPT Models, open the notebook in notepad and paste directly to avoid context limitiations for uploaded files. \n",
    "\n",
    "- [Anthropic's Claude](https://claude.ai/)\n",
    "\n",
    "- [Google's Gemini 2.5](https://aistudio.google.com/prompts/new_chat)\n",
    "\n",
    "These are all State of the Art, Long Context Models with Reasoning Capability.  This enables longer scripts to be coded with a more consistent output and reduced errors. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Clear image outputs before saving and uploading.  The file size should be around 66KB.\n",
    "</div>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f52e6",
   "metadata": {},
   "source": [
    "## üåä OPTION 1: FLO-2D: Calculate Flow x Depth and Save back to HDF\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b>\n",
    "\n",
    "- **Objective**: Create a Python script to manipulate HDF5 file data.\n",
    "- **File Path**: `Data\\Hdf5\\TIMDEPNC.HDF5`\n",
    "- **Data Tasks**:\n",
    "  - **Add Table `dep_x_vel`**: Multiply depth and velocity data.\n",
    "  - **Add Table `dep_x_sqvel`**: Multiply depth by velocity squared.\n",
    "- **Groups and Datasets**:\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/FLOW DEPTH`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/MAX VEL`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "- **Operations**:\n",
    "  - **Delete Existing Datasets**: Check and delete existing datasets `dep_x_vel` and `dep_x_sqvel` if present.\n",
    "  - **Calculate and Store New Data**: Compute and store new datasets for `dep_x_vel` and `dep_x_sqvel`.\n",
    "- **Dependencies**: Utilize `h5py` for HDF5 interaction and `numpy` for mathematical operations.\n",
    "- **Request**: Provide a Python script that executes the above operations as described.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36650a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc08207",
   "metadata": {},
   "source": [
    "# üåä OPTION 2: FLO-2D Flood Wave Arrival Time\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>GPT Prompt:</b>\n",
    "\n",
    "Assuming the notebook has been run and the xarrays above are present, add a code cell for FLO-2D that will find the time stamp of each grid cell, at the time where it exceeds 1ft in depth.  This indicates the first arrival of the flood wave. Create a function to find this and calculate time_to_1ft and save the daaset back to the hdf.  The function should overwrite the dataset in the hdf if it exists.  I should also plot a map of the flood wave arrival time time in hr.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25432b61",
   "metadata": {},
   "source": [
    "# üåä OPTION 3: RAS 2D Flood Wave Arrival Time\n",
    "\n",
    "'Assuming the notebook has been run and the xarrays above are present, add a code cell similar to Option 2, but for HEC-RAS 2D`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c146e1",
   "metadata": {},
   "source": [
    "# üåä OPTION 4: RAS 2D Time of Max WSEL\n",
    "\n",
    "Assuming the notebook has been run and the xarrays above are present, add a code cell that will find the timestamp of the max wsel of each cell, calculate time_to_max_wsel and map it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c67bae",
   "metadata": {},
   "source": [
    "# üåä OPTION 5: FLO-2D Plot Depth x Velocity\n",
    "\n",
    "\n",
    "Access the depth x velocity table and plot a depth x velocity plot for grid element number 5020.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f74ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5f9e7",
   "metadata": {},
   "source": [
    "# üåä Exporting Data to Other Formats\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "\n",
    "Provide a comprehensive list of file formats that can be used to export the data in this notebook.  Favor free and open source solutions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb0565",
   "metadata": {},
   "source": [
    "# Insert LLM Output Here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
