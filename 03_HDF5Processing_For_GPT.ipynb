{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb547134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Base path automatically set to: c:\\GH\\ASFPM-LLM-Data-Management-Workshop\n"
     ]
    }
   ],
   "source": [
    "# Automatically set base path to the project directory where the notebook is running\n",
    "from pathlib import Path\n",
    "\n",
    "# This gets the directory where the current notebook is located\n",
    "base_path = Path.cwd()\n",
    "\n",
    "print(f\"üìÇ Base path automatically set to: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pzQ2WIjuqtq6",
   "metadata": {
    "id": "pzQ2WIjuqtq6"
   },
   "source": [
    "# üìä HDF5 Data Processing with Python and ChatGPT\n",
    "\n",
    "Welcome to **HDF5 Data Processing**! In this session, we will use **ChatGPT**, **HDF5**, and **Python** to efficiently store, manipulate, and analyze large datasets.\n",
    "\n",
    "### Enable the Table of Contents Sidebar in Jupyter Notebook  \n",
    "For easier navigation:\n",
    "\n",
    "1. Click on **View** in Jupyter Notebook.\n",
    "2. Select **Left Sidebar** click **Show Table of Contents**.\n",
    "\n",
    "## üìå What You Will Learn\n",
    "1. Set up your computer for **Python scripting** and **HDF5 file processing**.\n",
    "2. Use **ChatGPT** to generate and debug **HDF5 queries**.\n",
    "3. Learn best practices for **efficient data management** with HDF5.\n",
    "4. Process and analyze **HDF5 datasets** using **Python and Numpy**.\n",
    "\n",
    "## üõ†Ô∏è Required Programs\n",
    "- **Python** (Version 3.12 or later)\n",
    "- **HDF5 View** (Library for hierarchical data storage)\n",
    "- **h5py** (Python library for working with HDF5 files)\n",
    "- **Numpy** (For reading and analyzing HDF5 data)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è Run the Test Cell  \n",
    "Before we begin, run the test cell below to check your setup.\n",
    "\n",
    "This test will:\n",
    "- ‚úÖ Verify that **HDF5 (h5py)** is available.\n",
    "- ‚úÖ Check if **Pandas** is installed.\n",
    "- ‚úÖ Confirm that an **HDF5 file can be created and accessed**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dd8d6c-3376-4145-a74f-2a5868b5b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking system setup...\n",
      "\n",
      "‚úÖ HDF5 (h5py) is available and working!\n",
      "‚úÖ Pandas imported successfully!\n",
      "üêç Python version: 3.12.9\n",
      "\n",
      "‚úÖ Test complete! If you see any ‚ùå marks, install missing dependencies before proceeding.\n"
     ]
    }
   ],
   "source": [
    "# Checking HDF5 and Pandas Setup\n",
    "\n",
    "print(\"üîç Checking system setup...\\n\")\n",
    "\n",
    "# Test h5py (HDF5 support)\n",
    "try:\n",
    "    import h5py\n",
    "    with h5py.File(\"test.hdf5\", \"w\") as f:\n",
    "        f.create_dataset(\"test_data\", data=[1, 2, 3, 4, 5])\n",
    "    print(\"‚úÖ HDF5 (h5py) is available and working!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå HDF5 test failed: {e}\")\n",
    "\n",
    "# Test Pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"‚úÖ Pandas imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Pandas is not installed. Run `pip install pandas`.\")\n",
    "\n",
    "# Confirm Python version\n",
    "import sys\n",
    "print(f\"üêç Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Test complete! If you see any ‚ùå marks, install missing dependencies before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d13ee",
   "metadata": {},
   "source": [
    "# üìä Using ChatGPT's Code Interpreter to Explore HDF5 Data Structure\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Use ChatGPT to help you understand and analyze HDF5 data. Before performing any analysis, it's important to understand the file structure as a reference, so ChatGPT can handle the coding, syntax, and data types and you can focus on describing the actual task you want to complete, such as mapping wsel/velocity or calculating shear stress.\n",
    "\n",
    "## ChatGPT Prompt for HDF Explorer Function\n",
    "\n",
    "Prompt ChatGPT:\n",
    "\n",
    "```\n",
    "Write a function that will recursively explore an HDF File path.  List all attributes, groups, datasets, compound datasets and objects.  For each, list the full path, type, data types, dataset dataspace and datatype,to ensure a complete readout of all info needed to extract data from the HDF path.  The function should be robust, comprehensive and provide information for all different data types that might be present.\n",
    "\n",
    "Use the provided TIMDEPNC.HDF5 and RAS_Muncie.p04.hdf to test the function by reading he following paths:\n",
    "\n",
    "\n",
    "TIMDEPNC.HDF5: TIMDEP OUTPUT RESULTS/\n",
    "\n",
    "RAS_Muncie.p04.hdf: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area\n",
    "\n",
    "```\n",
    "Provide the files and work with GPT until it achieves a desirable result.  \n",
    "\n",
    "Then, ask for a script for local execution:\n",
    "\n",
    "```\n",
    "Provide a jupyter notebook cell for my local notebook.  The HDF files are located in the same folder as the notebook, under the \"Data\\Hdf5\\\" subfolder.  \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9addc33c",
   "metadata": {},
   "source": [
    "![ChatGPT HDF Explorer](images/chatgpt-hdfexplorer.png)\n",
    "[ChatGPT Conversation for HDF Exploration](https://chatgpt.com/share/67f1ad34-2f60-8010-8381-6f3d449aa812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb1742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "def explore_hdf5(filepath, target_path=\"/\", indent=0):\n",
    "    \"\"\"\n",
    "    Recursively explores an HDF5 file and prints information about each group, dataset, and attribute.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath: str, path to the HDF5 file\n",
    "    - target_path: str, internal path in the HDF5 file to start exploration\n",
    "    - indent: int, current indentation level for pretty printing\n",
    "    \"\"\"\n",
    "    def print_info(name, obj, level):\n",
    "        spacing = ' ' * level\n",
    "        full_path = obj.name\n",
    "        obj_type = type(obj).__name__\n",
    "        print(f\"{spacing}Path: {full_path}\")\n",
    "        print(f\"{spacing}Type: {obj_type}\")\n",
    "\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"{spacing} - Shape: {obj.shape}\")\n",
    "            print(f\"{spacing} - Data type: {obj.dtype}\")\n",
    "            try:\n",
    "                print(f\"{spacing} - Dataspace (dims): {obj.shape}\")\n",
    "                print(f\"{spacing} - Datatype (HDF5 native): {obj.id.get_type().get_class()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{spacing} - Error reading dataspace/datatype: {e}\")\n",
    "        elif isinstance(obj, h5py.Group):\n",
    "            print(f\"{spacing} - Contains: {len(obj)} items\")\n",
    "\n",
    "        # Print attributes\n",
    "        if obj.attrs:\n",
    "            print(f\"{spacing} - Attributes:\")\n",
    "            for key, val in obj.attrs.items():\n",
    "                print(f\"{spacing}   * {key}: {val}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        def recursive_visit(group, level=0):\n",
    "            for key in group:\n",
    "                item = group[key]\n",
    "                print_info(key, item, level)\n",
    "                if isinstance(item, h5py.Group):\n",
    "                    recursive_visit(item, level + 2)\n",
    "\n",
    "        root = file[target_path]\n",
    "        print_info(target_path, root, indent)\n",
    "        if isinstance(root, h5py.Group):\n",
    "            recursive_visit(root, indent + 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26323b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring TIMDEPNC.HDF5:\n",
      "\n",
      "Path: /TIMDEP OUTPUT RESULTS\n",
      "Type: Group\n",
      " - Contains: 13 items\n",
      " - Attributes:\n",
      "   * Grouptype: [b'Generic']\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/CUMULATIVE FLOW QNET\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/CUMULATIVE FLOW QNET/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/CUMULATIVE FLOW QNET/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/CUMULATIVE FLOW QNET/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/CUMULATIVE FLOW QNET/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH\n",
      "  Type: Group\n",
      "   - Contains: 5 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/time_to_1_ft\n",
      "    Type: Dataset\n",
      "     - Shape: (8588,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (8588,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/MAX Q RES DIRECTION\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RES DIRECTION/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RES DIRECTION/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RES DIRECTION/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RES DIRECTION/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/MAX Q RESOLVED\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RESOLVED/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RESOLVED/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RESOLVED/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX Q RESOLVED/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/MAX VEL\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/MAX VEL LOC\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL LOC/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL LOC/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL LOC/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/MAX VEL LOC/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/SURFACE EXCHANGE\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/SURFACE EXCHANGE/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/SURFACE EXCHANGE/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/SURFACE EXCHANGE/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/SURFACE EXCHANGE/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (200,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (200,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (200, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (200, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/X-Coordinate\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/X-Coordinate/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/X-Coordinate/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/X-Coordinate/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/X-Coordinate/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (1, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate\n",
      "  Type: Group\n",
      "   - Contains: 4 items\n",
      "   - Attributes:\n",
      "     * Data Type: [0]\n",
      "     * DatasetCompression: [9]\n",
      "     * DatasetUnits: [b'ft or m']\n",
      "     * Grouptype: [b'DATASET SCALAR']\n",
      "     * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate/Maxs\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate/Mins\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate/Times\n",
      "    Type: Dataset\n",
      "     - Shape: (1,)\n",
      "     - Data type: float64\n",
      "     - Dataspace (dims): (1,)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "    Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\n",
      "    Type: Dataset\n",
      "     - Shape: (1, 8588)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (1, 8588)\n",
      "     - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/dep_x_sqvel\n",
      "  Type: Dataset\n",
      "   - Shape: (200, 8588)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200, 8588)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/dep_x_vel\n",
      "  Type: Dataset\n",
      "   - Shape: (200, 8588)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200, 8588)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/time_to_1_ft\n",
      "  Type: Dataset\n",
      "   - Shape: (8588,)\n",
      "   - Data type: float64\n",
      "   - Dataspace (dims): (8588,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the specified paths (FLO-2D)\n",
    "FLO_2D_timdepnc_file = os.path.join(\"Data\", \"Hdf5\", \"TIMDEPNC.HDF5\")\n",
    "print(\"Exploring TIMDEPNC.HDF5:\\n\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"TIMDEP OUTPUT RESULTS/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0eb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring RAS_Muncie.p04.hdf:\n",
      "\n",
      "Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area\n",
      "Type: Group\n",
      " - Contains: 3 items\n",
      "\n",
      "\n",
      "  Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations\n",
      "  Type: Group\n",
      "   - Contains: 18 items\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Inner Iteration Number\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Sum of inner-loop iterations over all outer-loop iterations'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Inner Max Volume Residual\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Max of inner-loop volume residual for last outer-loop iteration'\n",
      "       * Units: b'ft'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Inner Max Volume Residual Cell\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Cell location of max volume residual for inner-loop during last outer-loop iteration'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Max Face Velocity\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Maximum face velocity for 2D area'\n",
      "       * Units: b'ft/s'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Max Face Velocity Face\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Face ID of maximum face velocity for 2D area'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Max Water Surface\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Maximum water surface elevation for 2D area'\n",
      "       * Units: b'ft'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Max Water Surface Cell\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Cell of minimum water surface elevation for 2D area'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Min Water Surface\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Minimum water surface elevation for 2D area'\n",
      "       * Units: b'ft'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Min Water Surface Cell\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Cell of minimum water surface elevation for 2D area'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Outer Iteration Number\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Number of outer-loop iterations'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Outer Max Water Surface Correction\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Max water surface correction for last outer-loop iteration'\n",
      "       * Units: b'ft'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Outer Max Water Surface Correction Cell\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Cell location of max water surface correction at last outer-loop iteration'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Outer Status\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'1:ConvMax, 2:ConvRMS, 3:Stall, 4:Iter, 5:Small, -1:Max, -2:Div'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Percent Active Cells\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Percentage of active (wet) cells'\n",
      "       * Units: b'Percent by number of cells'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Time Step\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Units: b's'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Total Iteration Number\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: int32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 0\n",
      "     - Attributes:\n",
      "       * Description: b'Sum of inner and outer iterations'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Volume\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Percentage of active (wet) cells'\n",
      "       * Units: b'Acre-Feet'\n",
      "\n",
      "\n",
      "    Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Computations/Volume Error\n",
      "    Type: Dataset\n",
      "     - Shape: (289, 1)\n",
      "     - Data type: float32\n",
      "     - Dataspace (dims): (289, 1)\n",
      "     - Datatype (HDF5 native): 1\n",
      "     - Attributes:\n",
      "       * Description: b'Volume error for 2D area'\n",
      "       * Units: b'ft^3'\n",
      "\n",
      "\n",
      "  Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Face Velocity\n",
      "  Type: Dataset\n",
      "   - Shape: (289, 11164)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (289, 11164)\n",
      "   - Datatype (HDF5 native): 1\n",
      "   - Attributes:\n",
      "     * Can Interpolate: b'True'\n",
      "     * Can Plot: b'True'\n",
      "     * Columns: b'Faces'\n",
      "     * Coverage: b'Wet'\n",
      "     * Location: b'Faces'\n",
      "     * Maximum Value of Data Set: nan\n",
      "     * Name: b'Velocity'\n",
      "     * Orientation: b'Normal'\n",
      "     * Rows: b'Times'\n",
      "     * Units: b'ft/s'\n",
      "\n",
      "\n",
      "  Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\n",
      "  Type: Dataset\n",
      "   - Shape: (289, 5765)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (289, 5765)\n",
      "   - Datatype (HDF5 native): 1\n",
      "   - Attributes:\n",
      "     * Can Interpolate: b'True'\n",
      "     * Can Plot: b'True'\n",
      "     * Columns: b'Cells'\n",
      "     * Coverage: b'Wet'\n",
      "     * Location: b'Cells'\n",
      "     * Maximum Value of Data Set: 947.598388671875\n",
      "     * Minimum Value of Data Set: 924.9986572265625\n",
      "     * Name: b'Water Surface'\n",
      "     * Orientation: b'Scalar'\n",
      "     * Rows: b'Times'\n",
      "     * Units: b'ft'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the specified paths (HEC-RAS 2D)\n",
    "ras_file = os.path.join(\"Data\", \"Hdf5\", \"RAS_Muncie.p04.hdf\")\n",
    "print(\"\\nExploring RAS_Muncie.p04.hdf:\\n\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf74cd0",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a233c6a",
   "metadata": {},
   "source": [
    "# üìä User-Guided Data Exploration of HDF5 Files \n",
    "\n",
    "Now that we have a detailed description of the HDF's data contents, let's build functions to extract the data.  While this detailed information is no required, it is very helpful to reduce up-front errors and iterations.  To include this information in ChatGPT, just copy the cell output and paste into ChatGPT:   \n",
    "\n",
    "\n",
    "Go to the previous output cell:  \n",
    "![VS Code - Copy Cell Output](images/vscode-copycelloutput.png)  \n",
    "Copy the Cell Output and paste into ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5427d",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb6986",
   "metadata": {},
   "source": [
    "## Prompt for Extracting **FLO-2D Water Surface Elevation Results**\n",
    "\n",
    "Follow along by opening the file `Data/hdf5/TIMDEPNC.HDF5` in HDFView\n",
    "\n",
    "- **Water Surface Elevation Data**: Stored in TIMDEPNC.HDF5 a path `/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/`, containing water surface values for each grid element over time.\n",
    "- **Depth Data**: Stored in TIMDEPNC.HDF5 a path `/TIMDEP OUTPUT RESULTS/FLOW DEPTH/`, containing depth values for each grid element over time.\n",
    "- **Time Intervals**: Found in `TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times`, representing the time steps for the depth and velocity data.\n",
    "- **X and Y Coordinates** Found in TIMDEPNC.HDF5, `/TIMDEP OUTPUT RESULTS/X-Coordinate/Values` and `/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values`\n",
    "\n",
    "- **Instructions**: \n",
    "`Provide functions to extract Water Surface Elevation spatial time series to an Xarray and plot the xarray for the time step.  Use your code interpreter to test the functions and map the results to review.  Use the time step with the maximum depth to map results for review.`\n",
    "\n",
    "Follow-up: \n",
    "`Provide a code cell for my local notebook.  The local path for the HDF5 file is Data/Hdf5/TIMDEPNC.HDF5`\n",
    "\n",
    "\n",
    "1. Upload TIMDEPNC.HDF5 and ask ChatGPT to write a script that can print the structure of an hdf5 file, using it's Code Interpreter.\n",
    "3. Review outputs and provide any follow-up instructions needed. \n",
    "2. Ask for a code cell for your local jupyter notebook, providing your local data file paths to ChatGPT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION\n",
      "Type: Group\n",
      " - Contains: 4 items\n",
      " - Attributes:\n",
      "   * Data Type: [0]\n",
      "   * DatasetCompression: [9]\n",
      "   * DatasetUnits: [b'ft or m']\n",
      "   * Grouptype: [b'DATASET SCALAR']\n",
      "   * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Maxs\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Mins\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float64\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values\n",
      "  Type: Dataset\n",
      "   - Shape: (200, 8588)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200, 8588)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH\n",
      "Type: Group\n",
      " - Contains: 5 items\n",
      " - Attributes:\n",
      "   * Data Type: [0]\n",
      "   * DatasetCompression: [9]\n",
      "   * DatasetUnits: [b'ft or m']\n",
      "   * Grouptype: [b'DATASET SCALAR']\n",
      "   * TimeUnits: [b'Hours']\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Maxs\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Mins\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Times\n",
      "  Type: Dataset\n",
      "   - Shape: (200,)\n",
      "   - Data type: float64\n",
      "   - Dataspace (dims): (200,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values\n",
      "  Type: Dataset\n",
      "   - Shape: (200, 8588)\n",
      "   - Data type: float32\n",
      "   - Dataspace (dims): (200, 8588)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "  Path: /TIMDEP OUTPUT RESULTS/FLOW DEPTH/time_to_1_ft\n",
      "  Type: Dataset\n",
      "   - Shape: (8588,)\n",
      "   - Data type: float64\n",
      "   - Dataspace (dims): (8588,)\n",
      "   - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "Path: /TIMDEP OUTPUT RESULTS/X-Coordinate/Values\n",
      "Type: Dataset\n",
      " - Shape: (1, 8588)\n",
      " - Data type: float32\n",
      " - Dataspace (dims): (1, 8588)\n",
      " - Datatype (HDF5 native): 1\n",
      "\n",
      "\n",
      "Path: /TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\n",
      "Type: Dataset\n",
      " - Shape: (1, 8588)\n",
      " - Data type: float32\n",
      " - Dataspace (dims): (1, 8588)\n",
      " - Datatype (HDF5 native): 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL AND INCLUDE THE OUTPUT WITH YOUR REQUEST TO IMPROVE CONTEXT\n",
    "\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"TIMDEP OUTPUT RESULTS/FLOW DEPTH/\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\")\n",
    "explore_hdf5(FLO_2D_timdepnc_file, target_path=\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e8631",
   "metadata": {},
   "source": [
    "If you don't see something similar to this output, adjust the prompt, provide corrections or try again!\n",
    "\n",
    "![HDF-FLO-2D WSE Map in ChatGPT](images/hdf-FLO-2D_wse_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4503c",
   "metadata": {},
   "source": [
    "Try these follow-up prompts to explore the information available in the HDF: \n",
    "\n",
    "- `Now map the Flow Depth at the same time step\"`\n",
    "\n",
    "- `I want to create an animation of maximum water surface showing the full simulation.  Export as gif, and include instructions for inline jupyter installation of any required packages` (Note, this will require installing ffmpeg or additional packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65006401",
   "metadata": {},
   "source": [
    "[ChatGPT Conversation - FLO-2D HDF Data Extraction](https://chatgpt.com/share/67f29600-f218-8010-8a3e-42ea9300c60d)\n",
    "\n",
    "Code Cells from these follow-up requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the local path to your HDF5 file\n",
    "hdf5_path = \"Data/Hdf5/TIMDEPNC.HDF5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    # Load flow depth values and compute the timestep with maximum total depth\n",
    "    depth_values = f[\"/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values\"][:]\n",
    "    max_depth_timestep = np.argmax(np.sum(depth_values, axis=1))\n",
    "\n",
    "    # Load water surface elevation values and time\n",
    "    wse_values = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values\"][:]\n",
    "    wse_times = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\"][:]\n",
    "\n",
    "    # Load X and Y coordinates\n",
    "    x_coords = f[\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\"][:].flatten()\n",
    "    y_coords = f[\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\"][:].flatten()\n",
    "\n",
    "# Create an xarray DataArray for Water Surface Elevation\n",
    "wse_xr_flo = xr.DataArray(\n",
    "    data=wse_values,\n",
    "    dims=[\"time\", \"element\"],\n",
    "    coords={\"time\": wse_times, \"x\": ([\"element\"], x_coords), \"y\": ([\"element\"], y_coords)},\n",
    "    name=\"water_surface_elevation\"\n",
    ")\n",
    "\n",
    "# Extract data for the time step with maximum depth\n",
    "wse_at_max_depth = wse_xr_flo.sel(time=wse_times[max_depth_timestep])\n",
    "\n",
    "# Plot the water surface elevation at the selected time\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    wse_at_max_depth['x'],\n",
    "    wse_at_max_depth['y'],\n",
    "    c=wse_at_max_depth.values,\n",
    "    s=10,\n",
    "    cmap='viridis'\n",
    ")\n",
    "plt.colorbar(label='Water Surface Elevation (ft or m)')\n",
    "plt.title(f\"WSE at Time = {wse_at_max_depth.time.item():.2f} hours (Max Depth)\")\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract flow depth at the same time step (already found as max_depth_timestep)\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    depth_values = f[\"/TIMDEP OUTPUT RESULTS/FLOW DEPTH/Values\"][:]\n",
    "    wse_times = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\"][:]\n",
    "    x_coords = f[\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\"][:].flatten()\n",
    "    y_coords = f[\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\"][:].flatten()\n",
    "\n",
    "# Get depth data at max depth time step\n",
    "depth_at_max_time = depth_values[max_depth_timestep, :]\n",
    "\n",
    "# Plot the Flow Depth\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_coords,\n",
    "    y_coords,\n",
    "    c=depth_at_max_time,\n",
    "    s=10,\n",
    "    cmap='Blues'\n",
    ")\n",
    "plt.colorbar(label='Flow Depth (ft or m)')\n",
    "plt.title(f\"Flow Depth at Time = {wse_times[max_depth_timestep]:.2f} hours (Max Depth)\")\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c61fa",
   "metadata": {},
   "source": [
    "### OPTIONAL: SAVE ANIMATION AS GIF (TAKES 2-3 MINUTES TO PROCESS)\n",
    "\n",
    "### Install packages (run only once in your notebook)\n",
    "!pip install xarray matplotlib imageio --quiet\n",
    "\n",
    "### Imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm  # Optional: for progress bar\n",
    "import os\n",
    "\n",
    "### Load the HDF5 file\n",
    "hdf5_path = \"Data/Hdf5/TIMDEPNC.HDF5\"\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    wse_values = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Values\"][:]\n",
    "    wse_times = f[\"/TIMDEP OUTPUT RESULTS/WATER SURFACE ELEVATION/Times\"][:]\n",
    "    x_coords = f[\"/TIMDEP OUTPUT RESULTS/X-Coordinate/Values\"][:].flatten()\n",
    "    y_coords = f[\"/TIMDEP OUTPUT RESULTS/Y-Coordinate/Values\"][:].flatten()\n",
    "\n",
    "### Create a folder to store frames\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "### Generate and save each frame\n",
    "filenames = []\n",
    "for i in tqdm(range(len(wse_times))):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(x_coords, y_coords, c=wse_values[i], s=10, cmap='viridis')\n",
    "    plt.colorbar(label=\"Water Surface Elevation (ft or m)\")\n",
    "    plt.title(f\"WSE at Time = {wse_times[i]:.2f} hrs\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = f\"frames/frame_{i:03d}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "    filenames.append(fname)\n",
    "\n",
    "### Create GIF\n",
    "gif_path = \"wse_animation_FLO-2D.gif\"\n",
    "with imageio.get_writer(gif_path, mode='I', duration=0.2) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "### Clean up frames (optional)\n",
    "for filename in filenames:\n",
    "    os.remove(filename)\n",
    "\n",
    "print(f\"Animation saved as {gif_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ca3e1",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201e12c",
   "metadata": {},
   "source": [
    "## Prompt for Extracting **HEC-RAS 2D Water Surface Elevation Results**\n",
    "\n",
    "Follow along by opening the file `Data/hdf5/RAS_Muncie.p04.hdf` in HDFView\n",
    "\n",
    "- **Mesh Name Lookup**: 2D area names can be found in /Results/Unsteady/Geometry Info/2D Area(s).  Results are available for each 2D flow area, and the 2D area name is part of the path so it must be retrieved first (as a list).  In the example HDF file provided, flow_area_name is \"2D Interior Area\" (only one 2D area)\n",
    "\n",
    "- **Mesh Cell Centers** can be found here: `/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate`\n",
    "    \n",
    "- **Time Date Stamp**: Time stamps are available at this path: `/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp` Time Date Stamp is in this format: 02JAN1900 00:00:00\n",
    "\n",
    "- **Water Surface Elevation Time Series Results**  Water Surface Elevations for each Mesh Cell are located at `/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface`\n",
    "\n",
    "- **Instructions**: \n",
    "`Provide functions to extract Water Surface Elevation spatial time series to an Xarray and plot the xarray for the time step.  Use your code interpreter to test the functions and map the results to review.  Use the time step with the maximum depth to map results for review.`\n",
    "\n",
    "\n",
    "Instructions: \n",
    "1. Upload RAS_Muncie.p04.hdf and ask ChatGPT to write a script that can print the structure of an hdf5 file, using it's Code Interpreter.\n",
    "3. Review outputs and provide any follow-up instructions needed. \n",
    "2. Ask for a code cell for your local jupyter notebook, providing your local data file paths to ChatGPT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2d68a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Results/Unsteady/Geometry Info/2D Area(s)\n",
      "Type: Dataset\n",
      " - Shape: (1,)\n",
      " - Data type: |S64\n",
      " - Dataspace (dims): (1,)\n",
      " - Datatype (HDF5 native): 3\n",
      "\n",
      "\n",
      "Path: /Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\n",
      "Type: Dataset\n",
      " - Shape: (5765, 2)\n",
      " - Data type: float64\n",
      " - Dataspace (dims): (5765, 2)\n",
      " - Datatype (HDF5 native): 1\n",
      " - Attributes:\n",
      "   * Can Plot: b'False'\n",
      "   * Column: [b'X' b'Y']\n",
      "   * Row: b'Cell'\n",
      "\n",
      "\n",
      "Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\n",
      "Type: Dataset\n",
      " - Shape: (289,)\n",
      " - Data type: |S19\n",
      " - Dataspace (dims): (289,)\n",
      " - Datatype (HDF5 native): 3\n",
      "\n",
      "\n",
      "Path: /Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\n",
      "Type: Dataset\n",
      " - Shape: (289, 5765)\n",
      " - Data type: float32\n",
      " - Dataspace (dims): (289, 5765)\n",
      " - Datatype (HDF5 native): 1\n",
      " - Attributes:\n",
      "   * Can Interpolate: b'True'\n",
      "   * Can Plot: b'True'\n",
      "   * Columns: b'Cells'\n",
      "   * Coverage: b'Wet'\n",
      "   * Location: b'Cells'\n",
      "   * Maximum Value of Data Set: 947.598388671875\n",
      "   * Minimum Value of Data Set: 924.9986572265625\n",
      "   * Name: b'Water Surface'\n",
      "   * Orientation: b'Scalar'\n",
      "   * Rows: b'Times'\n",
      "   * Units: b'ft'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL AND INCLUDE THE OUTPUT WITH YOUR REQUEST TO IMPROVE CONTEXT\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Geometry Info/2D Area(s)\")\n",
    "explore_hdf5(ras_file, target_path=\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\")\n",
    "explore_hdf5(ras_file, target_path=\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e2f1e",
   "metadata": {},
   "source": [
    "Example Output from ChatGPT's Code Interpreter\n",
    "![ChatGPT - HEC-RAS 2D WSE Map](images/hdf-hecras_wse_map.png)\n",
    "[ChatGPT Conversation for Following Code Cells](https://chatgpt.com/share/67f2a034-5874-8010-9472-bb32f2f38252)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b85b16",
   "metadata": {},
   "source": [
    "Try these follow-up prompts to explore the information available in the HDF: \n",
    "\n",
    "- `Now map the Flow Depth at the same time step.  Use '/Geometry/2D Flow Areas/2D Interior Area/Cells Minimum Elevation' to calculate depth for each cell`\n",
    "\n",
    "- `Provide a code cell for my local jupyter notebook for both WSE and Depth. The local path is Data/Hdf5/RAS_Muncie.p04.hdf`\n",
    "\n",
    "- `I want to create an animation of maximum water surface showing the full simulation.  Export as gif, and include instructions for inline jupyter installation of any required packages` (Note, this will require installing ffmpeg or additional packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f96903-0e16-4d6b-a8a0-cc3bfe729004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Load the HDF5 file ===\n",
    "file_path = \"Data/Hdf5/RAS_Muncie.p04.hdf\"\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "\n",
    "    # === Load datasets ===\n",
    "    wse = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\"][()]\n",
    "    coords = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\"][()]\n",
    "    min_elev = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Minimum Elevation\"][()]\n",
    "    time_stamps = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\"][()].astype(str)\n",
    "\n",
    "# === Parse time and coordinates ===\n",
    "x_coords, y_coords = coords[:, 0], coords[:, 1]\n",
    "time_index = pd.to_datetime(time_stamps, format=\"%d%b%Y %H:%M:%S\")\n",
    "\n",
    "# === Create xarray for WSE ===\n",
    "wse_xr_ras = xr.DataArray(\n",
    "    wse,\n",
    "    dims=[\"time\", \"cell\"],\n",
    "    coords={\"time\": time_index, \"x\": (\"cell\", x_coords), \"y\": (\"cell\", y_coords)},\n",
    "    name=\"water_surface_elevation\",\n",
    "    attrs={\"units\": \"ft\"}\n",
    ")\n",
    "\n",
    "# === Identify timestep with maximum average WSE ===\n",
    "max_time_idx = wse_xr_ras.mean(dim=\"cell\").argmax().item()\n",
    "max_time = time_index[max_time_idx]\n",
    "wse_at_max = wse_xr_ras.sel(time=max_time)\n",
    "\n",
    "# === Calculate Flow Depth ===\n",
    "flow_depth = wse_at_max - min_elev\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    wse_xr_ras[\"x\"].values,\n",
    "    wse_xr_ras[\"y\"].values,\n",
    "    c=flow_depth.values,\n",
    "    cmap=\"Blues\",\n",
    "    s=8,\n",
    "    edgecolor=\"none\"\n",
    ")\n",
    "plt.colorbar(scatter, label=\"Flow Depth (ft)\")\n",
    "plt.title(f\"Flow Depth at Max WSE Time Step\\nTime: {max_time}\")\n",
    "plt.xlabel(\"X Coordinate (ft)\")\n",
    "plt.ylabel(\"Y Coordinate (ft)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dcda8-0717-4302-a1f5-6141aa5f62e9",
   "metadata": {},
   "source": [
    "### OPTIONAL: SAVE ANIMATION AS GIF (TAKES 2-3 MINUTES TO PROCESS)\n",
    "\n",
    "### Install required packages (run this in a Jupyter notebook cell)\n",
    "!pip install xarray matplotlib imageio --quiet\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "### --- Load Data ---\n",
    "file_path = \"Data/Hdf5/RAS_Muncie.p04.hdf\"\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    wse_data = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/2D Interior Area/Water Surface\"][()]\n",
    "    coords = hdf[\"/Geometry/2D Flow Areas/2D Interior Area/Cells Center Coordinate\"][()]\n",
    "    time_stamps = hdf[\"/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp\"][()].astype(str)\n",
    "\n",
    "### --- Set Up xarray ---\n",
    "x_coords, y_coords = coords[:, 0], coords[:, 1]\n",
    "time_index = pd.to_datetime(time_stamps, format=\"%d%b%Y %H:%M:%S\")\n",
    "\n",
    "wse_xr_ras = xr.DataArray(\n",
    "    wse_data,\n",
    "    dims=[\"time\", \"cell\"],\n",
    "    coords={\n",
    "        \"time\": time_index,\n",
    "        \"x\": (\"cell\", x_coords),\n",
    "        \"y\": (\"cell\", y_coords)\n",
    "    },\n",
    "    name=\"water_surface_elevation\"\n",
    ")\n",
    "\n",
    "### --- Prepare Animation ---\n",
    "filenames = []\n",
    "vmin, vmax = np.nanmin(wse_data), np.nanmax(wse_data)  # consistent color scale\n",
    "\n",
    "for i, t in tqdm(enumerate(wse_xr_ras.time.values), total=wse_xr_ras.sizes['time']):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sc = ax.scatter(wse_xr_ras.x, wse_xr_ras.y, c=wse_xr_ras.sel(time=t), cmap=\"viridis\", s=8, vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(sc, ax=ax, label=\"Water Surface Elevation (ft)\")\n",
    "    ax.set_title(f\"WSE Time: {pd.to_datetime(t).strftime('%Y-%m-%d %H:%M')}\")\n",
    "    ax.set_xlabel(\"X Coordinate (ft)\")\n",
    "    ax.set_ylabel(\"Y Coordinate (ft)\")\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"_frame_{i:04d}.png\"\n",
    "    plt.savefig(filename)\n",
    "    filenames.append(filename)\n",
    "    plt.close()\n",
    "\n",
    "### --- Create GIF ---\n",
    "with imageio.get_writer(\"wse_animation_RAS.gif\", mode=\"I\", duration=0.2) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "### --- Cleanup PNGs ---\n",
    "import os\n",
    "for filename in filenames:\n",
    "    os.remove(filename)\n",
    "\n",
    "print(\"‚úÖ Animation saved as wse_animation.gif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679aca8",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c46293",
   "metadata": {},
   "source": [
    "# üìä Using your Jupyter Notebook as Context to Add Functionality\n",
    "\n",
    "For the rest of the exercise, we will use the new line of reasoning models (o1), using this notebook as context.  \n",
    "\n",
    "Provide this notebook to any of the following models:\n",
    "\n",
    "- ChatGPT\n",
    "    - [o1](https://chatgpt.com/?model=o1)\n",
    "    - [o3-mini high](https://chatgpt.com/?model=o3-mini-high)  \n",
    "    \n",
    "    NOTE: For ChatGPT Models, open the notebook in notepad and paste directly to avoid context limitiations for uploaded files. \n",
    "\n",
    "- [Anthropic's Claude](https://claude.ai/)\n",
    "\n",
    "- [Google's Gemini 2.5](https://aistudio.google.com/prompts/new_chat)\n",
    "\n",
    "These are all State of the Art, Long Context Models with Reasoning Capability.  This enables longer scripts to be coded with a more consistent output and reduced errors. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Clear image outputs before saving and uploading.  The file size should be around 66KB.\n",
    "</div>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f52e6",
   "metadata": {},
   "source": [
    "## OPTION 1: FLO-2D: Calculate Flow x Depth and Save back to HDF\n",
    "\n",
    "- **Objective**: Create a Python script to manipulate HDF5 file data.\n",
    "- **File Path**: `Data\\Hdf5\\TIMDEPNC.HDF5`\n",
    "- **Data Tasks**:\n",
    "  - **Add Table `dep_x_vel`**: Multiply depth and velocity data.\n",
    "  - **Add Table `dep_x_sqvel`**: Multiply depth by velocity squared.\n",
    "- **Groups and Datasets**:\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/FLOW DEPTH`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "  - **Group `TIMDEP OUTPUT RESULTS/MAX VEL`**:\n",
    "    - **Dataset**: `Maxs` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Mins` - Shape: (200,), Dtype: float32\n",
    "    - **Dataset**: `Times` - Shape: (200,), Dtype: float64\n",
    "    - **Dataset**: `Values` - Shape: (200, 8588), Dtype: float32\n",
    "- **Operations**:\n",
    "  - **Delete Existing Datasets**: Check and delete existing datasets `dep_x_vel` and `dep_x_sqvel` if present.\n",
    "  - **Calculate and Store New Data**: Compute and store new datasets for `dep_x_vel` and `dep_x_sqvel`.\n",
    "- **Dependencies**: Utilize `h5py` for HDF5 interaction and `numpy` for mathematical operations.\n",
    "- **Request**: Provide a Python script that executes the above operations as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36650a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc08207",
   "metadata": {},
   "source": [
    "## OPTION 2: FLO-2D Flood Wave Arrival Time\n",
    "\n",
    "`Assuming the notebook has been run and the xarrays above are present, add a code cell for FLO-2D that will find the time stamp of each grid cell, at the time where it exceeds 1ft in depth.  This indicates the first arrival of the flood wave. Create a function to find this and calculate time_to_1ft and save the daaset back to the hdf.  The function should overwrite the dataset in the hdf if it exists.  I should also plot a map of the flood wave arrival time time in hr.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1c2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25432b61",
   "metadata": {},
   "source": [
    "# üìä OPTION 3: RAS 2D Flood Wave Arrival Time\n",
    "\n",
    "'Assuming the notebook has been run and the xarrays above are present, add a code cell similar to Option 2, but for HEC-RAS 2D`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3bf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c146e1",
   "metadata": {},
   "source": [
    "# üìä OPTION 4: RAS 2D Time of Max WSEL\n",
    "\n",
    "'Assuming the notebook has been run and the xarrays above are present, add a code cell that will find the timestamp of the max wsel of each cell, calculate time_to_max_wsel and map it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f74ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5f9e7",
   "metadata": {},
   "source": [
    "# Exporting Data to Other Formats\n",
    "\n",
    "`Provide a comprehensive list of file formats that can be used to export the data in this notebook.  Favor free and open source solutions.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb0565",
   "metadata": {},
   "source": [
    "# Insert LLM Output Here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "flo2d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
