{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8620a78a",
   "metadata": {},
   "source": [
    "# üîµ ‚ö™ üîµ LiDAR to Smooth Ground Surface Using PDAL\n",
    "\n",
    "## Overview\n",
    "\n",
    "This workflow efficiently converts LiDAR point cloud data (LAZ/LAS) to a smooth ground surface raster (GeoTIFF) using PDAL (Point Data Abstraction Library). The pipeline is optimized for both speed and output quality.\n",
    "\n",
    "## ‚öôÔ∏è Key Processing Steps Explained\n",
    "\n",
    "### 1. Ground Point Extraction (`filters.range`)\n",
    "- **Function**: Isolates only ground-classified points (Class 2 in LAS/LAZ format)\n",
    "- **Importance**: Creates a clean dataset containing only terrain surface points\n",
    "- **Performance Impact**: Reduces data volume for subsequent processing steps\n",
    "\n",
    "### 2. Outlier Removal (`filters.outlier`)\n",
    "- **Function**: Identifies and removes statistical outliers\n",
    "- **Parameters**:\n",
    "  - `mean_k`: 12 - Number of nearest neighbors to analyze\n",
    "  - `multiplier`: 2.0 - Statistical threshold for outlier identification  \n",
    "- **Importance**: Eliminates noise and erroneous points that would create artifacts\n",
    "- **Output Quality**: Creates smoother surfaces by removing spikes and holes\n",
    "\n",
    "### 3. Data Thinning (`filters.decimation`)\n",
    "- **Function**: Systematically reduces point density by keeping every nth point\n",
    "- **Parameter**: `step`: 3 - Keeps every 3rd point (reduces data by ~67%)\n",
    "- **Performance Impact**: Significantly improves processing speed\n",
    "- **Trade-off**: Slight reduction in detail, but maintains overall terrain characteristics\n",
    "\n",
    "### 4. Rasterization with Smoothing (`writers.raster`)\n",
    "- **Function**: Converts point cloud to raster grid with interpolation\n",
    "- **Parameters**:\n",
    "  - `resolution`: 2.0 - Output cell size in units of the source data\n",
    "  - `output_type`: \"idw\" - Inverse Distance Weighting interpolation\n",
    "  - `radius`: 6.0 - Search radius for influencing points\n",
    "  - `power`: 2.0 - Controls how quickly influence diminishes with distance\n",
    "- **Importance**: Creates continuous surface with natural transitions between points\n",
    "- **Output Quality**: IDW produces a smooth surface while respecting the actual elevation values\n",
    "\n",
    "### 5. Multi-threading Optimization\n",
    "- **Function**: Utilizes multiple CPU cores for parallel processing\n",
    "- **Parameter**: `thread_count`: num_cores - Automatically uses all available cores\n",
    "- **Performance Impact**: Near-linear speedup with number of cores\n",
    "\n",
    "## ‚è±Ô∏è Performance Optimization Techniques\n",
    "\n",
    "1. **Strategic Filtering Order**:\n",
    "   - Extract ground first to minimize data volume for subsequent steps\n",
    "   - Apply computationally expensive operations (outlier removal) on reduced dataset\n",
    "\n",
    "2. **Data Reduction**:\n",
    "   - Point classification filtering removes non-ground data\n",
    "   - Decimation reduces overall point count by 67%\n",
    "   - Outlier removal eliminates noise that would slow triangulation\n",
    "\n",
    "3. **Efficient Interpolation Method**:\n",
    "   - IDW provides excellent speed/quality balance compared to triangulation\n",
    "   - Configurable radius and power parameters for fine-tuning\n",
    "\n",
    "4. **Parallel Processing**:\n",
    "   - Automatic detection and utilization of all available CPU cores\n",
    "   - Thread count matching to hardware capabilities\n",
    "\n",
    "## üõ†Ô∏è Adjustable Parameters for Different Requirements\n",
    "\n",
    "### For Higher Resolution Output\n",
    "- Decrease `resolution` (e.g., 1.0)\n",
    "- Decrease `step` in decimation (e.g., 2)\n",
    "- Increase `radius` in IDW interpolation\n",
    "\n",
    "### For Faster Processing\n",
    "- Increase `resolution` (e.g., 5.0)\n",
    "- Increase `step` in decimation (e.g., 5 or 8)\n",
    "- Decrease `mean_k` in outlier filter\n",
    "\n",
    "### For Smoother Output\n",
    "- Increase `radius` in IDW\n",
    "- Increase `power` parameter (e.g., 3.0)\n",
    "- Use a larger `mean_k` value for outlier detection\n",
    "\n",
    "## Alternative Approaches\n",
    "\n",
    "For different requirements, consider these alternative filter combinations:\n",
    "\n",
    "1. **Triangle-Based Approach**:\n",
    "   - Uses `filters.delaunay` and `filters.faceraster`\n",
    "   - Creates triangulated irregular network (TIN) before rasterization\n",
    "   - Better for preserving sharp features but slower\n",
    "\n",
    "2. **Moving Least Squares Approach** (if available):\n",
    "   - Uses `filters.mls` before rasterization\n",
    "   - Creates mathematically smooth surfaces\n",
    "   - Computationally intensive but produces very smooth results\n",
    "\n",
    "3. **Grid-Based Approach**:\n",
    "   - Uses direct grid projection methods\n",
    "   - Fastest option but potentially less smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936adeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to create a ground surface raster from LiDAR data using PDAL.\n",
    "It includes steps for filtering, decimation, outlier removal, and rasterization.\n",
    "The script is designed to be run in a Python environment with PDAL installed.\n",
    "It is assumed that the PDAL library and its dependencies are properly installed and configured.\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Determine the number of cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "input_file = os.path.join(file_path, \"USGS_LPC_AZ_MaricopaPinal_2020_B20_w0401n3720.laz\")\n",
    "output_file = os.path.join(file_path, \"ground_surface_smooth.tif\")\n",
    "\n",
    "# Enhanced pipeline for a smoother surface\n",
    "pipeline_dict = {\n",
    "  \"pipeline\":[\n",
    "    input_file,\n",
    "    # Extract ground points\n",
    "    {\n",
    "        \"type\": \"filters.range\",\n",
    "        \"limits\": \"Classification[2:2]\"\n",
    "    },\n",
    "    # Moderate thinning - balance between speed and detail\n",
    "    {\n",
    "        \"type\": \"filters.decimation\",\n",
    "        \"step\": 4  # Keep every 4th point\n",
    "    },\n",
    "    # Remove outliers for a smoother surface\n",
    "    {\n",
    "        \"type\": \"filters.outlier\",\n",
    "        \"method\": \"statistical\",\n",
    "        \"mean_k\": 8,\n",
    "        \"multiplier\": 2.0\n",
    "    },\n",
    "    # Use delaunay triangulation for smoother interpolation\n",
    "    {\n",
    "        \"type\": \"filters.delaunay\"\n",
    "    },\n",
    "    # Create a smooth raster surface from the triangulation\n",
    "    {\n",
    "        \"type\": \"filters.faceraster\",\n",
    "        \"resolution\": 1.0\n",
    "    },\n",
    "    # Write the raster output\n",
    "    {\n",
    "        \"type\": \"writers.raster\",\n",
    "        \"filename\": output_file,\n",
    "        \"gdaldriver\": \"GTiff\"\n",
    "    }\n",
    "  ],\n",
    "  \"thread_count\": num_cores\n",
    "}\n",
    "\n",
    "# Create and execute the pipeline\n",
    "start_time = time.time()\n",
    "pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "count = pipeline.execute()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Processed {count} points using {num_cores} threads\")\n",
    "print(f\"Total processing time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfea6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to create a ground surface raster from multiple LiDAR files using PDAL.\n",
    "It includes steps for filtering, decimation, outlier removal, and rasterization.\n",
    "The script processes all .laz files in the specified directory.\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# Determine the number of cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Directory containing LAZ files\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "\n",
    "# Get a list of all LAZ files in the directory\n",
    "laz_files = glob.glob(os.path.join(file_path, \"*.laz\"))\n",
    "\n",
    "print(f\"Found {len(laz_files)} LAZ files to process.\")\n",
    "\n",
    "# Process each LAZ file\n",
    "for input_file in laz_files:\n",
    "    # Create output filename based on input filename\n",
    "    base_name = os.path.basename(input_file)\n",
    "    output_name = os.path.splitext(base_name)[0] + \"_ground_surface.tif\"\n",
    "    output_file = os.path.join(file_path, output_name)\n",
    "    \n",
    "    print(f\"\\nProcessing file: {base_name}\")\n",
    "    print(f\"Output will be saved as: {output_name}\")\n",
    "    \n",
    "    # Enhanced pipeline for a smoother surface\n",
    "    pipeline_dict = {\n",
    "      \"pipeline\":[\n",
    "        input_file,\n",
    "        # Extract ground points\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        },\n",
    "        # Moderate thinning - balance between speed and detail\n",
    "        {\n",
    "            \"type\": \"filters.decimation\",\n",
    "            \"step\": 4  # Keep every 4th point\n",
    "        },\n",
    "        # Remove outliers for a smoother surface\n",
    "        {\n",
    "            \"type\": \"filters.outlier\",\n",
    "            \"method\": \"statistical\",\n",
    "            \"mean_k\": 8,\n",
    "            \"multiplier\": 2.0\n",
    "        },\n",
    "        # Use delaunay triangulation for smoother interpolation\n",
    "        {\n",
    "            \"type\": \"filters.delaunay\"\n",
    "        },\n",
    "        # Create a smooth raster surface from the triangulation\n",
    "        {\n",
    "            \"type\": \"filters.faceraster\",\n",
    "            \"resolution\": 1.0\n",
    "        },\n",
    "        # Write the raster output\n",
    "        {\n",
    "            \"type\": \"writers.raster\",\n",
    "            \"filename\": output_file,\n",
    "            \"gdaldriver\": \"GTiff\"\n",
    "        }\n",
    "      ],\n",
    "      \"thread_count\": num_cores\n",
    "    }\n",
    "    \n",
    "    # Create and execute the pipeline\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "        count = pipeline.execute()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Successfully processed {count} points using {num_cores} threads\")\n",
    "        print(f\"Processing time: {elapsed_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_name}: {e}\")\n",
    "\n",
    "print(\"\\nAll files processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cae12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Single LiDAR processing workflow for hydrologic/hydraulic modeling:\n",
    "1. Process LiDAR tile with consistent parameters\n",
    "2. Create consistent, lower-resolution surfaces\n",
    "3. Generate a seamless mosaic suitable for visualization and modeling\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "\n",
    "# This is the most reliable approach - merge the point clouds BEFORE rasterization\n",
    "\n",
    "# Find all LAZ files\n",
    "file_path = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "laz_files = glob.glob(os.path.join(file_path, \"*.laz\"))\n",
    "output_merged = os.path.join(file_path, \"merged_ground_surface.tif\")\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Create a PDAL pipeline that merges all point clouds first, then creates a single raster\n",
    "pipeline_dict = {\n",
    "  \"pipeline\": [\n",
    "    # Use all LAZ files as input\n",
    "    *laz_files,\n",
    "    {\n",
    "        \"type\": \"filters.merge\"  # Merge all point clouds into one\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filters.range\",\n",
    "        \"limits\": \"Classification[2:2]\"  # Extract ground points\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filters.outlier\",\n",
    "        \"method\": \"statistical\",\n",
    "        \"mean_k\": 8,\n",
    "        \"multiplier\": 2.0\n",
    "    },\n",
    "    # Create a single TIN across the entire dataset\n",
    "    {\n",
    "        \"type\": \"filters.delaunay\"\n",
    "    },\n",
    "    # Rasterize the entire TIN at once - eliminates edge effects\n",
    "    {\n",
    "        \"type\": \"filters.faceraster\",\n",
    "        \"resolution\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"writers.raster\",\n",
    "        \"filename\": output_merged,\n",
    "        \"gdaldriver\": \"GTiff\",\n",
    "        \"gdalopts\": \"COMPRESS=LZW,BIGTIFF=YES\"\n",
    "    }\n",
    "  ],\n",
    "  \"thread_count\": num_cores\n",
    "}\n",
    "\n",
    "# Execute the pipeline\n",
    "pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "count = pipeline.execute()\n",
    "print(f\"Processed {count} points into a seamless raster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2347af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scalable LiDAR processing workflow for hydrologic/hydraulic modeling:\n",
    "1. Process LiDAR tiles with consistent parameters\n",
    "2. Create consistent, lower-resolution surfaces\n",
    "3. Generate a seamless mosaic suitable for visualization and modeling\n",
    "\"\"\"\n",
    "import pdal\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "from osgeo import gdal\n",
    "import subprocess\n",
    "\n",
    "def process_lidar_scalable_no_buffer(lidar_dir, output_dir, target_resolution=10.0, target_epsg=2223):\n",
    "    \"\"\"\n",
    "    Process multiple LiDAR files for hydraulic modeling with a focus on scalability\n",
    "    Uses only standard PDAL filters that are widely available\n",
    "    \n",
    "    Parameters:\n",
    "    - lidar_dir: Directory containing LAZ files\n",
    "    - output_dir: Directory for output files\n",
    "    - target_resolution: Resolution in feet (default 10ft for hydraulic modeling)\n",
    "    - target_epsg: Target coordinate system (default EPSG:2223)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Find all LAZ files\n",
    "    laz_files = glob.glob(os.path.join(lidar_dir, \"*.laz\"))\n",
    "    print(f\"Found {len(laz_files)} LAZ files to process\")\n",
    "    \n",
    "    # Number of cores to use\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    \n",
    "    # Step 2: Process each LAZ file with extended boundaries\n",
    "    processed_tiles = []\n",
    "    \n",
    "    for i, laz_file in enumerate(laz_files):\n",
    "        print(f\"\\nProcessing file {i+1}/{len(laz_files)}: {os.path.basename(laz_file)}\")\n",
    "        \n",
    "        # Create output filename\n",
    "        base_name = os.path.splitext(os.path.basename(laz_file))[0]\n",
    "        output_raster = os.path.join(output_dir, f\"{base_name}_ground_{target_resolution}ft.tif\")\n",
    "        processed_tiles.append(output_raster)\n",
    "        \n",
    "        # Create PDAL pipeline without buffer (not available in your installation)\n",
    "        pipeline_dict = {\n",
    "          \"pipeline\": [\n",
    "            laz_file,\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"Classification[2:2]\"  # Extract ground points\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.decimation\",\n",
    "                \"step\": 4  # Reduce point count for large datasets\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"statistical\",\n",
    "                \"mean_k\": 8,\n",
    "                \"multiplier\": 2.0\n",
    "            },\n",
    "            # Use delaunay triangulation for a smooth surface\n",
    "            {\n",
    "                \"type\": \"filters.delaunay\"\n",
    "            },\n",
    "            # Create raster at the target resolution (e.g., 10ft)\n",
    "            {\n",
    "                \"type\": \"filters.faceraster\",\n",
    "                \"resolution\": target_resolution\n",
    "            },\n",
    "            # Write the raster output\n",
    "            {\n",
    "                \"type\": \"writers.raster\",\n",
    "                \"filename\": output_raster,\n",
    "                \"gdaldriver\": \"GTiff\",\n",
    "                \"gdalopts\": \"COMPRESS=LZW,BIGTIFF=YES\"\n",
    "            }\n",
    "          ],\n",
    "          \"thread_count\": num_cores\n",
    "        }\n",
    "        \n",
    "        # Execute the pipeline\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            pipeline = pdal.Pipeline(json.dumps(pipeline_dict))\n",
    "            count = pipeline.execute()\n",
    "            end_time = time.time()\n",
    "            print(f\"  Processed {count} points in {end_time - start_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {base_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Step 3: Create a seamless mosaic with enhanced blending\n",
    "    print(\"\\nCreating seamless mosaic with enhanced blending...\")\n",
    "    \n",
    "    # Output for the merged result\n",
    "    mosaic_output = os.path.join(output_dir, f\"seamless_mosaic_{target_resolution}ft.tif\")\n",
    "    reprojected_output = os.path.join(output_dir, f\"seamless_mosaic_{target_resolution}ft_epsg{target_epsg}.tif\")\n",
    "    \n",
    "    # Create a VRT to merge the tiles\n",
    "    vrt_path = os.path.join(output_dir, \"temp_mosaic.vrt\")\n",
    "    \n",
    "    # Use gdalbuildvrt command line with additional options\n",
    "    gdalbuildvrt_cmd = [\n",
    "        'gdalbuildvrt',\n",
    "        '-resolution', 'highest',\n",
    "        '-a_srs', 'EPSG:4326',  # Ensure correct source SRS\n",
    "        '-r', 'average',\n",
    "        vrt_path\n",
    "    ] + processed_tiles\n",
    "    \n",
    "    subprocess.run(gdalbuildvrt_cmd)\n",
    "    \n",
    "    # Create mosaic with a very large blending distance to compensate for lack of buffering\n",
    "    gdalwarp_cmd = [\n",
    "        'gdalwarp',\n",
    "        '-co', 'COMPRESS=LZW',\n",
    "        '-co', 'BIGTIFF=YES',\n",
    "        '-r', 'cubic',  # Cubic interpolation for smoother results\n",
    "        '-wo', 'CUTLINE_BLEND_DIST=100',  # Very large blend distance (10x the resolution)\n",
    "        '-wo', 'UNIFIED_SRC_NODATA=YES',\n",
    "        '-dstnodata', '-9999',  # Explicit NoData value\n",
    "        '-multi',  # Use multithreading\n",
    "        vrt_path,\n",
    "        mosaic_output\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(gdalwarp_cmd)\n",
    "    \n",
    "    # Additional step: Fill any remaining NoData gaps\n",
    "    filled_mosaic = os.path.join(output_dir, f\"filled_mosaic_{target_resolution}ft.tif\")\n",
    "    gdal_fillnodata_cmd = [\n",
    "        'gdal_fillnodata.py',\n",
    "        '-md', '10',  # Maximum search distance in pixels\n",
    "        '-si', '0',   # No smoothing iterations\n",
    "        mosaic_output,\n",
    "        filled_mosaic\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(gdal_fillnodata_cmd)\n",
    "    \n",
    "    # Reproject to target CRS\n",
    "    if target_epsg != 0:\n",
    "        print(f\"Reprojecting to EPSG:{target_epsg}...\")\n",
    "        gdalwarp_reproj_cmd = [\n",
    "            'gdalwarp',\n",
    "            '-co', 'COMPRESS=LZW',\n",
    "            '-co', 'BIGTIFF=YES',\n",
    "            '-r', 'cubic',\n",
    "            '-t_srs', f'EPSG:{target_epsg}',\n",
    "            '-multi',\n",
    "            filled_mosaic,\n",
    "            reprojected_output\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(gdalwarp_reproj_cmd)\n",
    "    \n",
    "    # Clean up\n",
    "    if os.path.exists(vrt_path):\n",
    "        os.remove(vrt_path)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Seamless mosaic: {filled_mosaic}\")\n",
    "    if target_epsg != 0:\n",
    "        print(f\"Reprojected mosaic: {reprojected_output}\")\n",
    "    \n",
    "    return filled_mosaic, reprojected_output if target_epsg != 0 else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your directories and parameters\n",
    "    lidar_directory = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\"\n",
    "    output_directory = r\"C:\\Users\\Public\\Documents\\FLO-2D PRO Documentation\\Example Projects\\Self Help Kit Gila\\ElevationData\\LiDAR\\Processed\"\n",
    "    \n",
    "    # Set resolution to 10 feet (common for hydraulic modeling)\n",
    "    resolution = 10.0\n",
    "    \n",
    "    # Process the data with the modified approach\n",
    "    process_lidar_scalable_no_buffer(lidar_directory, output_directory, resolution, target_epsg=2223)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flo2d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
